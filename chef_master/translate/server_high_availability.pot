# SOME DESCRIPTIVE TITLE.
# Copyright (C) This work is licensed under a Creative Commons Attribution 3.0 Unported License.
# This file is distributed under the same license as the Chef Docs package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Chef Docs \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2014-09-08 14:52-0700\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

#: ../source/server_high_availability.rst:8
# 8783dcb80cd841b3b3ad14d5f5c0a325
msgid "High Availability"
msgstr ""

#: ../../includes_server_ha/includes_server_ha.rst:4
# 46a1f9d7832f4107b988a4f30d1b0a68
msgid "The |chef server| can operate in a high availability configuration that provides automated load balancing and failover for stateful components in the system architecture. This type of configuration typically splits the servers into two segments: front-end and back-end machines:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha.rst:8
# 57f722677b9a43949dfeafa1d03b7906
msgid "Front-end machines handle requests to the |api chef server| and access to the web user interface. Front-end machines should be load balanced and scaled horizontally by increasing the number of servers available to handle requests."
msgstr ""

#: ../../includes_server_ha/includes_server_ha.rst:10
# 1028b7fac17e444db47610abdc78801a
msgid "Back-end machines handle data storage and retrieval, messaging and routing, analytics processing, and search. Back-end machines should be configured for failover using block level replication."
msgstr ""

#: ../source/server_high_availability.rst:12
# 59f7f6070d224b85be4e2a68cdbcac96
msgid "For |chef server| 12, the following high availability configurations are supported:"
msgstr ""

#: ../source/server_high_availability.rst:14
#: ../source/server_high_availability.rst:18
# 7fee84dd1ff34669ad303376bb11c1d3
# 153f9a8e62cb46f390b67b7047c300b6
msgid "DRBD"
msgstr ""

#: ../source/server_high_availability.rst:15
#: ../source/server_high_availability.rst:58
# 3687e12f591046e8bbcb13b3b1668bad
# 07ad120530434bf6be4554eda69dbf88
msgid "AWS"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd.rst:4
# 0ec5cf6385fa46e09ef1acface1689c9
msgid "|drbd| is a supported high availability configuration option for the |chef server|."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd.rst:8
# 88994b5e831247d1a419429aa5cc4d0f
msgid "Front-end machines are scaled horizontally, and then load balanced using a hardware load balancer, |ssl| off-loading, and round-robin as the load balancing algorithm."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd.rst:10
# d9fb5143eb6345ff9fc956c02966d073
msgid "Back-end machines are scaled vertically by adding memory, processing power, and faster disks to increase throughput, by adding faster disks and dedicated network interface cards to increase the reliability of |drbd| and the responsiveness of the |chef server|. Failover is achieved using:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd.rst:12
# aaa5bf95237f4c3aa5cd337e3d8c6aed
msgid "Asynchronous block level replication of logical volume managers, positioned between the two back-end machines"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd.rst:13
# 21c87f5d0bee4013a71fa9e340582c38
msgid "A primary and backup cluster election using |vrrp| over unicast TCP/IP and |keepalived|"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd.rst:14
# bb0bcfafcf3546efb231f1289f131b1f
msgid "A virtual IP address to the primary |chef server| that is maintained based on the results of the election done by |keepalived|"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd.rst:16
# 4592163920dc47a49e7f9d86bccbe436
msgid "When the primary |chef server| in the cluster fails, the |vrrp| heartbeat will stop. At this point, the backup server will begin transitioning to the primary state by:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd.rst:18
# 49983db269204743b32feefe4ce7484d
msgid "Assigning the virtual IP address and sending a ``proxy-arp``; this step transitions the virtual IP address, which means traffic will flow to the back-end |chef server| while it makes the transition to becoming the primary |chef server|."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd.rst:19
# 1c8c7e206fca413a9cb940baf4a49ec5
msgid "Attempting to take over as the primary |chef server| for the |drbd| device."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd.rst:20
# 3500663c15d74447a8beb26fd1303abd
msgid "Starting all of the back-end services."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd.rst:22
# fb15b45efa634fc88014006caa6df50a
msgid "For more information about |drbd|, see http://www.drbd.org."
msgstr ""

#: ../source/server_high_availability.rst:22
# 54d803e2e702493a97467fdeb2f3991e
msgid "Graceful Transitions"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_graceful_transitions.rst:4
# d53294056f134b4690bd7a2d5bf069cf
msgid "The |keepalived| service manages the |vrrp| and cluster transitions. It should be running on both the primary and secondary servers. To transition from the primary to the secondary, simply run the following command on the primary |chef server|:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_graceful_transitions.rst:10
# 2cae708685974941802256a7ada4513d
msgid "This will initiate a failover from the primary to the secondary |chef server| and will cause the current primary |chef server| to remove the virtual IP address, stop all services, unmount the |drbd| device, and then become the secondary |chef server| for the |drbd| device. Meanwhile, the secondary |chef server| will undergo a similar process, but become the primary |chef server|."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_graceful_transitions.rst:12
# 3da467184d6549349c83f257133349e3
msgid "To view the progress of this transition, use the following command:"
msgstr ""

#: ../source/server_high_availability.rst:26
# dced1df7472b4d82bfbcac18b402ac7c
msgid "Split Brains"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_split_brain.rst:4
# fd1785f9b43846589ea137b5c56f8bcc
msgid "A ``split-brain`` event is a concept of clustered computing systems in which the cluster loses its heartbeat communication channel and becomes two unconnected pieces. Recovery from a ``split-brain`` event can be a complex issue and different clustering software packages use different methods."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_split_brain.rst:6
# f94a5828a2f94d92b8a299e262a6b8c9
msgid "Failures happen, so completely preventing a ``split-brain`` event is not an absolute possibility. However, it is possible to alleviate some of the issues that crop up in any ``split-brain`` event scenarios by maxing out the heartbeat network bandwidth and optimizing transfer protocols."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_split_brain.rst:8
# 1abaa7d3ba764f58b05c1e0895818ea0
msgid "|drbd| is a shared-nothing system. Data is replicated between hosts over a dedicated network link rather than stored on a central network-attached storage (NAS) or storage attached network (SAN) to which all hosts are connected. The most critical issue for storage in a |ha| topology is loss of or corruption of data. Maximizing the amount of data that can be passed over the wire while all systems are up and running correctly minimizes the chance that something will be lost or unrecoverable if a host goes down."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_split_brain.rst:10
# bc970a9b20ee4c50bff3e4aa77095947
msgid "At any given time, only one |drbd| host has ``userland`` access to data, This host is referred to as the primary node. The other host runs the |drbd| daemon, but cannot mount the storage into the file system. The secondary node receives information from the primary node, and then replicates disk actions on its local storage copy (even if the partition looks like it doesn’t have a file system to which a ``mount`` command can be sent)."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_split_brain.rst:12
# a63d74b0b29c4a90b6c7b1ea8bf7aca9
msgid "The approach that |drbd| takes to ``split-brain`` event situations is to degrade all partners still alive to secondary status, and then wait for manual intervention. This is called auto-fencing, with a goal of minimizing the potential for damage to your data. When you lose one of the partners in a |ha| topology, a bit of manual intervention is required to ensure that the disks aren’t in a bad state and can be brought back up. These scenarios are discussed below, including suggestions for diagnosing and recovering from each scenario."
msgstr ""

#: ../source/server_high_availability.rst:30
# f0dcb8f5611b425fadd2e8109aeae03e
msgid "Custom Handlers"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_handlers.rst:4
# 53d6f4b4e4e3483cad625c8d7d54c4de
msgid "|drbd| configuration allows for custom handlers when a ``split-brain`` event happens. The basic handler sends a notification email to a configurable email address so the issue can be investigated."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_handlers.rst:6
# fcc7967e81d041dda5268b6fc41a29f3
msgid "The ``drbd.conf`` file that is used with the |chef server| specifies other built-in actions that may be taken in certain fault scenarios:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_handlers.rst:14
# ceaaef6591c2411898fa8e55cc6a78da
msgid "What this means:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_handlers.rst:16
# c695c3db98d64c60a56a6f7d3814c1c0
msgid "after-sb-0pri: A ``split-brain`` event has been detected and neither node is the primary node. The ``discard-younger-primary`` action will roll back any changes made on the last host that was the primary node."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_handlers.rst:17
# b25f902cea5a4cd99e564f02153be619
msgid "after-sb-1pri: A ``split-brain`` event has been detected and only one node believes that it was the primary node when the event happened. The ``discard-secondary`` action will continue operations on the primary node and will assume that the secondary node was lost."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_handlers.rst:18
# c00e5fe2a0f14ca5ad2c3eab5eb4cbc0
msgid "after-sb-2pri: A ``split-brain`` event has been detected and both nodes believed they were primary nodes. The ``call-pri-lost-after-sb`` action will attempt to apply the ``discard-younger-primary`` from the ``0pri`` configuration to determine which host should be the primary node. Once determined, the other host takes action to become the secondary node."
msgstr ""

#: ../source/server_high_availability.rst:34
# 30d47608d9d44e54ab955d2d4f06858d
msgid "Assumptions"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_assumptions.rst:4
# 08409706ac3f463c9d5f0848e9891d17
msgid "The following assumptions exist when the |chef server| is deployed in a |ha| topology:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_assumptions.rst:6
# db807644853a40ab853c26218551cab2
msgid "The back-end processes run on two hosts: ``BE1`` and ``BE2``. ``BE1`` is the |drbd| primary and the master |chef server|; ``BE2`` is the |drbd| secondary and the |chef server| backup"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_assumptions.rst:7
# bb69c73f5ada480492e81a29e4224cdc
msgid "The back-end uses |keepalived| and a dedicated network interface for heartbeat"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_assumptions.rst:8
# 2ff3aa184cc14fbaa9d1d4dcba0cccf9
msgid "The back-end uses |drbd| for file redundancy"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_assumptions.rst:10
# 06148f418e124f79b4984d978f00ce18
msgid "On each host, its own status is reported first, and then the status of its remote partner."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_assumptions.rst:12
# 9599d4211f3c4e8db5ebbf85ccac5d33
msgid "When both the primary and secondary nodes are running and behaving as expected, the contents of ``/proc/drbd`` on the primary node will look similar to the following:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_assumptions.rst:21
# 5e61754232504edd9a549192c5744a9d
msgid "On the secondary node, the status will look similar to the following:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_assumptions.rst:30
# b0aad389ec604625a03e84fdd64f5310
msgid "For information about the settings in this file, see the |drbd| website: http://www.drbd.org/users-guide/ch-admin.html."
msgstr ""

#: ../source/server_high_availability.rst:38
# 829e798ff4844cceb859d89fc2cdd3b0
msgid "Failure Scenarios"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario.rst:4
# f94380d101d741f28802e60030a9bd4e
msgid "The following four common scenarios are discussed:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario.rst:6
# d447adf6d7cd4ef683ca721a0616984b
msgid "Back-end server #2 fails gracefully (all data is synced)"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario.rst:7
# 3e274e45b30d430bbb1766b99ab6b130
msgid "Back-end server #2 hard fails badly (unsynced data)"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario.rst:8
# 4410555fd9b04089a12d45f89eef4a55
msgid "Back-end server #1 fails gracefully (all data is synced)"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario.rst:9
# 082f1e77dc5646d98ecc08d4567600a4
msgid "Back-end server #1 hard fails badly (unsynced data)"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario.rst:10
# 37ef892224cf4585a766d4ec057fcca8
msgid "Both hosts are up as secondary, and the |chef server| is unhappy"
msgstr ""

#: ../source/server_high_availability.rst:42
# f02b5dbe40fb46b19fe2ad0ba8f5ebb3
msgid "Scenarios 1 and 2"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario_1and2.rst:4
# b5720176451e43db8448fd00d32902bb
msgid "When the acting backup server fails, |drbd| on the master will continue to function in primary mode, whether the |drbd| on the secondary was shut down gracefully or became unavailable unexpectedly. Verify that |drbd| is functioning by running ``drbdadm role pc0`` on the primary:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario_1and2.rst:12
# f08d79e720324110b79eeac7e5ae297e
msgid "You can see the full status by running cat ``/proc/drbd``:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario_1and2.rst:21
# 993c6940477945799439e83e6a83dd67
msgid "The disk partition is still mounted into the file system and can be used as normal."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario_1and2.rst:23
# 743426291cb74fd39c5d92d30b1bce0c
msgid "When the secondary becomes available again, two things may happen:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario_1and2.rst:25
# b0ae647314104530980c989b9890c39c
msgid "If the status of the secondary reports ``Inconsistent`` or ``UpToDate`` without manual intervention, all is well."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario_1and2.rst:26
# d80e15d2c7944a9097f179e9e3f648c3
msgid "If it remains ``DUnknown``, |drbd| on the secondary can be manually restarted and it will start to sync. The ``DUnknown`` status is the report which indicates that |drbd| sees no network connection to its partner."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario_1and2.rst:28
# 4eece4e94f8e4426bd8bc65d8e34fab4
msgid "The last field in the ``/prod/drbd`` file (``oos``) reports how far the primary is out of sync with its partner. If the secondary is down and there are a lot of writes on the primary, this number will increase. For example:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario_1and2.rst:37
# e19b86b23ed44656973b68092761605d
msgid "When the disks return to a synced state, that field will return to ``0``. While the secondary is syncing, status about the syncing process will be shown for both hosts. For the secondary, something like the following:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario_1and2.rst:47
# 44d981ecd91b4ee9b291a2c267fd729f
msgid "and for the primary, something like the following:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario_1and2.rst:58
# 1d66cb32f3b84cdd807259ab9df5e20d
msgid "Eventually the hosts will quiesce and report ``ds:UpToDate/UpToDate``. Depending on how long the secondary was down, how much data was written to the primary in the interim, and the speed of the shared network, this process could be nearly instantaneous, or could take several minutes. The processes used to manage the |chef server| should not require manipulation in any way during this recovery."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario_1and2.rst:60
# bbb1ad154f844692bc3189451897ad61
msgid "If the secondary host is lost completely, a new host can be installed in its place, the device built, and then |drbd| started. The new host will pair with the existing primary, sync data, and be ready to take over if necessary."
msgstr ""

#: ../source/server_high_availability.rst:46
# cce1e16af7c742f4b255b2667e774858
msgid "Scenario 3"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario_3.rst:4
# b493ae71c9e14a21a377277c965dd15a
msgid "Trouble starts when the |drbd| primary is the host that becomes unavailable. The |drbd| process on the secondary makes no assumptions about whether or not it should automatically take over, based on the split-brain configurations in the ``drbd.conf`` file."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario_3.rst:6
# d522efe2045c4ce69f7448e2ace46183
msgid "Basically, what this means is that when the primary becomes unavailable to the secondary without an explicit takeover being initiated, the secondary will assume that it itself is the wrong, ``split-brained`` host, and is the one unconnected and incorrect. It will take no automatic action."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario_3.rst:8
# 7f8debe4f5e843949e4f095433f2664e
msgid "The status of the secondary will look something like the following:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario_3.rst:17
# 2df597c2115a4ef79b680adf5cde1044
msgid "The ``ds:UpToDate/Unknown`` is important; it indicates that the secondary has all the data that was on the primary and won’t lose anything if it is promoted."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario_3.rst:19
# d32c6b984fbd404f87a306718832cfd4
msgid "If it is verified that the primary host is going to be down for a while, the secondary can be promoted to primary:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario_3.rst:25
# f33ce0a654274ca698bfe4a97d5afb76
msgid "at that point the status will change to something like the following:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario_3.rst:34
# 1d383025dcca4113b65164346b9e805f
msgid "Notice that ``ro`` is now ``ro:Primary/Unknown``. The |chef server| can now be recovered by entering the following command:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario_3.rst:40
# f5c96c528d9641c782816a06e7866acf
msgid "This will start up the configured services and the |chef server| will be master on this host."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario_3.rst:42
# ce16b47f1d59445e9bdff571c9d6f222
msgid "If the original primary can be brought back online, the cluster management script run by |keepalived| will try to do a |drbd| takeover, based on that host’s original primary |chef server| master status."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario_3.rst:44
# f302c1e0bfb8400981265556a8d4c9d9
msgid "The first thing it will do is attempt to promote itself to |drbd| primary, which will fail if the disk has been written to at all while this host was down, and |keepalived| will be unable to transition back to the original master. This leaves the pair of servers in a good state, with the second back-end box as the |drbd| primary |chef server| master."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario_3.rst:46
# 119640f8121643eaa8aaa69ff8ce94e2
msgid "|drbd| on the first back-end server will sync to the second back-end server and will become the clean secondary |fqdn|."
msgstr ""

#: ../source/server_high_availability.rst:50
# a6706bd29e09460c80deee5d4da267aa
msgid "Scenario 4"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario_4.rst:4
# d7a58eb145634fcfabd5bb49f14605ff
msgid "So far, the scenarios have not described any data loss. When the hosts in the high availability pair are synced, either can be lost and the data will be safe."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario_4.rst:6
# 0fea2d7c31fc4b3c9a79ef1c3299acd8
msgid "If you get to a situation in which the primary host is lost and unrecoverable, but the last status of the |drbd| pair was reporting that the secondary node was in an ``Inconsistent`` state, it is very likely that some data will be lost. The |drbd| status on the remaining host will look something like the following:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario_4.rst:15
# 51a3cdb2dc6c4fc581c2c16df433ca54
msgid "As long as good source code management is practiced with cookbooks and other files in the |chef repo|, any missing bits can be re-uploaded after there is a working cluster. In some cases, newly-created users or organizations will need to be re-created. Other actions, such as |chef client| runs and uploads may fail while the cluster is in an ``Inconsistent`` state, but will be fine after there is a working cluster."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario_4.rst:17
# e624ae823bdc459d9c4ff0ffc46533ae
msgid "When the primary back-end server has been lost while the secondary back-end server is in an ``Inconsistent`` state and it's not going to be back online quickly, the best thing to do is to provision another host to become the new |chef server| cluster partner for the secondary back-end server, and then build it out. If the new host has an IP address that is different from the primary back-end server, change the configuration on the secondary back-end server, and then reconfigure."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario_4.rst:19
# 99a3ff8f5e2d4463b04fbe1470c17c1c
msgid "In this situation, the |chef server| may be freaking out a bit, so turn off the daemons using the ``chef-server-ctl stop`` command."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario_4.rst:21
# 0cf64946c43e4505b0c903b3ac8c783b
msgid "Once the new host is identified and the |drbd| devices on that host are ready, bring up |drbd| and get it talking to the secondary back-end server. This secondary server should not want to be the primary server; it should be waiting for the old primary server to return. Start up |drbd| on the new host and verify that it is listening on the correct port and that the status in ``/proc/drbd`` is reporting that the host is up, but in the ``WFConnect: waiting for connection`` state."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario_4.rst:23
# 598e735e63c74fd8a17cfec372998638
msgid "By the time you get the new node is up, the secondary back-end server may have taken itself into ``standalone`` mode, which means that it is no longer listening on the network port. In this situation, run the following commands to get the secondary back-end server to talk to the new node:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario_4.rst:29
#: ../../includes_server_ha/includes_server_ha_drbd_scenario_5.rst:12
# 46f5c072edb84398b5fdbeea799b65e8
# 04af7dbccda04d6db3744aad81d4f0f8
msgid "and:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario_4.rst:35
# 7a67371343684ec680dc2f3e6e066cd7
msgid "At this point, the new host should be synchronizing with the secondary back-end server. The secondary back-end server will forget all about the data it was missing from the now-gone primary back-end server, and the process of bringing the |chef server| back online can begin."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario_4.rst:37
# 879df5a489ac497c96bf803d22f04190
msgid "Running a fast network between the primary and secondary hosts, and keeping it full throttle for |drbd| transfers, will go a long way to mitigating the any damage that may be done in the event of a loss of the primary from an un-synced cluster."
msgstr ""

#: ../source/server_high_availability.rst:54
# 008d8c944fce47faa21cd66c7ba5ba7a
msgid "Scenario 5"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario_5.rst:4
# 92e69ef937374815901e3d4adc465663
msgid "Sometimes |drbd| hedges its bets, and puts both nodes in a pair into secondary mode. When this happens, you can look at the contents of ``/proc/drbd`` on both hosts and see if either of them is showing out of sync. If they are both ``oos:0``, just pick one and promote it to primary using the ``drbdadm primary pc0`` command. If one or both of the hosts is out of sync, choose the one with the lower amount of ``oos`` and promote it to primary."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario_5.rst:6
# 3d7b8afab145498d89b4d3335dce4edf
msgid "If the chosen node won’t promote, run the following commands on the other host to reset its disk state:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario_5.rst:18
# eeee3d0116a1465997eabfdd9254d7df
msgid "That will tell |drbd| to abandon what is on the node and start over, and should allow it to sync with the primary."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_aws.rst:4
# a9aa65ef3c464ffc98a00020e551d332
msgid "AWS is a supported high availability configuration option for the |chef server|."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_aws.rst:8
# c20c1c1123384a03b70465d8bbf89c15
msgid "Machines are stored as |amazon ebs| volumes. A passive node monitors the availabilty of the active node, and will take over if required."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_aws.rst:10
# 32d388eefe624a8d97308a61583699d9
msgid "For more information about |amazon ebs|, see http://aws.amazon.com/ebs/."
msgstr ""

#: ../source/server_high_availability.rst:62
# 9600549426e44e64a2e700da110ad91e
msgid "Configuration"
msgstr ""

#: ../source/server_high_availability.rst:65
# 4ebf678f5c564f82b0bb8490377280a8
msgid "To configure AWS for high availability, first create machines in AWS. Two back-end machines are required. Create as many front-end machine as required."
msgstr ""

#: ../source/server_high_availability.rst:67
# c08d48d4722b433d9bf5e08b6937cb9b
msgid "Create an EBS volume. Attach it to the primary back-end machine. (The rest of these instructions occur on the primary back-end machine.)"
msgstr ""

#: ../source/server_high_availability.rst:68
# a5fbeb317bb7443cb28d0fd14b3841cd
msgid "Install the |chef server|."
msgstr ""

#: ../source/server_high_availability.rst:69
# 448938659cbc484e9ac983baf337eb9d
msgid "Install the chef-ha package."
msgstr ""

#: ../source/server_high_availability.rst:70
#: ../source/server_high_availability.rst:144
# 769e7acf22004486ad2cabbcfd9af3e1
# 485b3f54036b4e21935b4d389957d49a
msgid "Run the following command:"
msgstr ""

#: ../source/server_high_availability.rst:76
# 38ebc3eb3d214a52871ee98e32bdb465
msgid "Create a file named ``chef-server.rb`` and add the following settings and appy the appropriate values for ``aws_access_key_id``, ``aws_secret_access_key``, and ``ebs_volume_id``:"
msgstr ""

#: ../source/server_high_availability.rst:86
# 2c86cd5a552141c08037ac8a240fec2b
msgid "Run the following series of commands:"
msgstr ""

#: ../source/server_high_availability.rst:92
#: ../source/server_high_availability.rst:98
#: ../source/server_high_availability.rst:104
#: ../source/server_high_availability.rst:110
#: ../source/server_high_availability.rst:116
# b2c866772bf14d63a5163c9ef5e06043
# d10c72d73f8c47f0aeda0625ca15cf13
# f1838f56b65c44438b0a81466154ed34
# f32a5ebe12b94c0c8a7cfbf8192a59e8
# 9c4dbf64eaa8427c87bc856770921ed6
msgid "then:"
msgstr ""

#: ../source/server_high_availability.rst:122
# b41ee83b2e964a7c9a5eb39ea63129cc
msgid "and then:"
msgstr ""

#: ../source/server_high_availability.rst:128
# fdf462300ab24a8fab62926e90ec9b8a
msgid "Proceed with the installation as normal."
msgstr ""

#: ../source/server_high_availability.rst:129
# 322da23cf7734b19950ea58dfb1b8885
msgid "Run the one of the following commands on all nodes:"
msgstr ""

#: ../source/server_high_availability.rst:135
# 683fd7f4a42b48c8b0d37840a819612c
msgid "or:"
msgstr ""

#: ../source/server_high_availability.rst:141
# f4535b8d71f441dcbf958df22363567b
msgid "where ``FQDN`` is the address of the passive back-end."
msgstr ""

#: ../source/server_high_availability.rst:143
# 0cfe773aa692431f82cce5ea6c9c3619
msgid "Install packages on all nodes."
msgstr ""

#: ../source/server_high_availability.rst:152
# e8546904f14940899ac94b707ef5fa0a
msgid "Check HA Status"
msgstr ""

#: ../../includes_api_chef_server/includes_api_chef_server_endpoint_status.rst:4
# 646339f619aa4a66a39476d35df34f8a
msgid "The ``/_status`` endpoint can be used to check the status of communications between the front and back end servers. This endpoint is located at ``/_status`` on the front end servers."
msgstr ""

#: ../../includes_api_chef_server/includes_api_chef_server_endpoint_status.rst:6
# 93c846c117f54a98979f23ff7df1244b
msgid "**Request**"
msgstr ""

#: ../../includes_api_chef_server/includes_api_chef_server_endpoint_status.rst:12
# 93f5a96e1a2d4ebb90a7aabccd22e7e5
msgid "This method has no request body."
msgstr ""

#: ../../includes_api_chef_server/includes_api_chef_server_endpoint_status.rst:14
# 178d2de43ba848ef900ad91480298632
msgid "**Response**"
msgstr ""

#: ../../includes_api_chef_server/includes_api_chef_server_endpoint_status.rst:16
# b09c54c47dae4d4bad0258ccf2680d5f
msgid "The response will return something like the following:"
msgstr ""

#: ../../includes_api_chef_server/includes_api_chef_server_endpoint_status.rst:30
# e743fab03d9a4ec1ba2b64c27a0af63d
msgid "**Response Codes**"
msgstr ""

#: ../../includes_api_chef_server/includes_api_chef_server_endpoint_status.rst:36
# bf07191ca5c142518f3a80c468131704
msgid "Response Code"
msgstr ""

#: ../../includes_api_chef_server/includes_api_chef_server_endpoint_status.rst:37
# 772db7f7bcd540dd843bdb8fd5c2efc5
msgid "Description"
msgstr ""

#: ../../includes_api_chef_server/includes_api_chef_server_endpoint_status.rst:38
# 44ce91c01369445fbeddc0004ec4255b
msgid "``200``"
msgstr ""

#: ../../includes_api_chef_server/includes_api_chef_server_endpoint_status.rst:39
# 8212d6cad994464ebc4e7217f6c463fd
msgid "All communications are OK."
msgstr ""

#: ../../includes_api_chef_server/includes_api_chef_server_endpoint_status.rst:40
# 3229710108af4878867848564208c429
msgid "``500``"
msgstr ""

#: ../../includes_api_chef_server/includes_api_chef_server_endpoint_status.rst:41
# 510c99e8dcce44b8bd653e50feb8ce13
msgid "One (or more) services are down. For example:"
msgstr ""

