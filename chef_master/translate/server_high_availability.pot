# SOME DESCRIPTIVE TITLE.
# Copyright (C) This work is licensed under a Creative Commons Attribution 3.0 Unported License.
# This file is distributed under the same license as the Chef Docs package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Chef Docs \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2014-01-16 13:47\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

#: ../source/server_high_availability.rst:8
# 36d4a95d54ad492ebf6fc008c249592e
msgid "High Availability"
msgstr ""

#: ../../includes_server_ha/includes_server_ha.rst:4
# 6c7ae81ef8cc4f22be207ffbdff7f89a
msgid "|chef server oec| can operate in a high availability configuration that provides automated failover for stateful components in the system architecture. This configuration splits servers into two segments: front-end and back-end servers. The front-end servers handle requests to the user interface and requests that use the |api chef server|. The back-end servers handle data storage and retrieval, which consists of:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha.rst:6
# 8775685d49a843beae446c9ba6035626
msgid "|couch db|"
msgstr ""

#: ../../includes_server_ha/includes_server_ha.rst:7
# f76ded41f0d2409b8b03144861fe0b09
msgid "|postgresql|"
msgstr ""

#: ../../includes_server_ha/includes_server_ha.rst:8
# 9f5773d3d4fd4771bac0edfd36163d56
msgid "|opscode solr|"
msgstr ""

#: ../../includes_server_ha/includes_server_ha.rst:9
# 1a73a5d91d724a6cb8be07bf65fbedce
msgid "|rabbitmq|"
msgstr ""

#: ../../includes_server_ha/includes_server_ha.rst:10
# 633ec130e3294a5b93425a53a07d91f6
msgid "|redis|"
msgstr ""

#: ../../includes_server_ha/includes_server_ha.rst:11
# 04dde5a0c2cc4bbbbad6579cb1dda605
msgid "Cookbook data"
msgstr ""

#: ../../includes_server_ha/includes_server_ha.rst:13
# 636f54fa4ea64c05bc13c563b9d3d563
msgid "Failover on the back-end servers is achieved using the following:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha.rst:15
# b33eb63a02174a068e77469bcaa18451
msgid "Asynchronous block level replication of logical volume managers using |drbd|, positioned between two back-end servers"
msgstr ""

#: ../../includes_server_ha/includes_server_ha.rst:16
# af1e3c05a0084deab7dd4828f045e6e7
msgid "A primary and backup cluster election using |vrrp| over unicast TCP/IP and |keepalived|"
msgstr ""

#: ../../includes_server_ha/includes_server_ha.rst:17
# 3bfde1ee2a934d57952160363f1cec7a
msgid "A virtual IP address to the primary server, maintained based on the results of the election done by |keepalived|"
msgstr ""

#: ../../includes_server_ha/includes_server_ha.rst:21
# dc9635c861064052a6a1f6c7c8f5a8f4
msgid "The front-end servers require load-balancers. |company_name| recommends:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha.rst:23
# 8423d434326744c1b8c5f5e5b4f4b55d
msgid "Hardware load-balancers (such as |f5| or |netscalar|)"
msgstr ""

#: ../../includes_server_ha/includes_server_ha.rst:24
# 035a0b915dd84306b428fa6b2e0df2e3
msgid "|ssl| off-loading"
msgstr ""

#: ../../includes_server_ha/includes_server_ha.rst:25
# 66194379e93c47018b3e9677aeb9c830
msgid "Round-robin as the load-balancing algorithm"
msgstr ""

#: ../source/server_high_availability.rst:13
# 9b9c3539df1149ef807ce1fe9a968b3f
msgid "Scalability"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scalability.rst:4
# 9f5a1b353a514b3891fae78e210bae2d
msgid "Scalability for front-end servers is achieved by horizontally scaling the number of servers."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scalability.rst:6
# 9e97f81d3b7d4141be872189f0cab5e8
msgid "Scalability for back-end servers is achieved by vertically scaling the servers. For example, adding memory, CPU, and faster disks will all increase throughput from the back-end servers. Faster disks, and dedicated network interface cards will all increase the reliability of |drbd| and the responsiveness of |chef server oec|."
msgstr ""

#: ../source/server_high_availability.rst:17
# 5501f57a0f8b48a489f914b5d352ed43
msgid "Failover and Recovery"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_failover.rst:4
# a10dda691d1f4774815a75bf45db25f1
msgid "When the primary server in the cluster fails, the |vrrp| heartbeat will stop. At this point the backup server will begin transitioning to the primary state, which involves:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_failover.rst:6
# 847c25adabf947b0a17c11867a857dae
msgid "Assigning the virtual IP address and sending a ``proxy-arp``"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_failover.rst:7
# cd5168e288144ad38ea50e77f992eadf
msgid "Attempting to take-over as the primary server for the |drbd| device"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_failover.rst:8
# dc6d7c9096fb4c8099bf398851e5ef8e
msgid "Starting all of the back-end services"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_failover.rst:10
# e4a2c22f62c847c0b39eae4a356d5547
msgid "The first step is transitioning the virtual IP address, which means that traffic will flow to the backup server while it makes the transition to being the primary server."
msgstr ""

#: ../source/server_high_availability.rst:21
# 4358b07dd5ad4f2caff917ed34518258
msgid "Graceful Transitions"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_transitions.rst:4
# da5178ce1dbf43dca19726383adde745
msgid "The |keepalived| service manages the |vrrp| and cluster transitions. It should be running on both the primary and secondary servers. To transition from the primary to the secondary, simply run the following on the primary:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_transitions.rst:10
# d298b07714064a4389a3936ab020afb7
msgid "which will initiate a failover from the primary to the secondary. This will cause the current primary to:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_transitions.rst:12
# e9e12636f57047f0b2450af803ce2d98
msgid "Remove the virtual IP address."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_transitions.rst:13
# 49f6927d8d844ed6b628ba99a947bf18
msgid "Stop the services."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_transitions.rst:14
# c3202e76bf7446afb3100ac63b0486dc
msgid "Unmount the |drbd| device."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_transitions.rst:15
# 848a663e0b4a408cbcef00cc360fec6b
msgid "Becoming secondary for the |drbd| device."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_transitions.rst:17
# a207fbec0a0545d99f2ae9ccecf65c0c
msgid "Meanwhile, the backup will be undergoing the same steps as listed above. Use the ``ha-status`` option to view the progress:"
msgstr ""

#: ../source/server_high_availability.rst:25
# 196ff856fd8c48b58247a97ce611978b
msgid "Status"
msgstr ""

#: ../../includes_api_chef_server/includes_api_chef_server_endpoint_status.rst:4
# 056878548bbe409893348caa6d0727b6
msgid "The ``/_status`` endpoint can be used to check the status of communications between the front and back end servers. This endpoint is located at ``/_status`` on the front end servers."
msgstr ""

#: ../../includes_api_chef_server/includes_api_chef_server_endpoint_status.rst:6
# 67fa72a30dd342c1b5b7a6d975949e90
msgid "**Request**"
msgstr ""

#: ../../includes_api_chef_server/includes_api_chef_server_endpoint_status.rst:12
# 7e8e49b1c0fc4178b6d6e11b2abe67a2
msgid "This method has no request body."
msgstr ""

#: ../../includes_api_chef_server/includes_api_chef_server_endpoint_status.rst:14
# 428d4e78f6c54ee7a95430594e3710e7
msgid "**Response**"
msgstr ""

#: ../../includes_api_chef_server/includes_api_chef_server_endpoint_status.rst:16
# ebb88157a0c447589adfcaebc543133b
msgid "The response will return something like the following:"
msgstr ""

#: ../../includes_api_chef_server/includes_api_chef_server_endpoint_status.rst:31
# 6cb80de30eaa449ab3097a306e0a50d6
msgid "**Response Codes**"
msgstr ""

#: ../../includes_api_chef_server/includes_api_chef_server_endpoint_status.rst:37
# 335d39d4044446cf911bda94c08aec49
msgid "Response Code"
msgstr ""

#: ../../includes_api_chef_server/includes_api_chef_server_endpoint_status.rst:38
# ef85ac04c9224d6090df1ae4869e4494
msgid "Description"
msgstr ""

#: ../../includes_api_chef_server/includes_api_chef_server_endpoint_status.rst:39
# 0d9891b0a2044a3c98b3daca506ce0a2
msgid "``200``"
msgstr ""

#: ../../includes_api_chef_server/includes_api_chef_server_endpoint_status.rst:40
# 763305a1f0ec4f4eaf844ba5b21d9259
msgid "All communications are OK."
msgstr ""

#: ../../includes_api_chef_server/includes_api_chef_server_endpoint_status.rst:41
# ab042008303c4b88a1477b9928825b1c
msgid "``500``"
msgstr ""

#: ../../includes_api_chef_server/includes_api_chef_server_endpoint_status.rst:42
# fb86ed77aa41439987eccc957aac859d
msgid "One (or more) services are down. For example:"
msgstr ""

#: ../source/server_high_availability.rst:29
# f309efd95043466880505e24029d23c4
msgid "DRBD"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd.rst:4
# 94ddeed9849749b3ab261c4477da9c66
msgid "|drbd| is used as part of a |ha| topology for |chef server oec|. More information about |drbd| is available from their website: http://www.drbd.org."
msgstr ""

#: ../source/server_high_availability.rst:33
# e1c8169b65d644d3923c39db0f6a62fd
msgid "Split Brains"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_split_brain.rst:4
# c503ed34830448cba05ffa1935bed24c
msgid "A ``split-brain`` event is a concept of clustered computing systems in which the cluster loses its heartbeat communication channel and becomes two unconnected pieces. Recovery from a ``split-brain`` event can be a complex issue and different clustering software packages use different methods."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_split_brain.rst:6
# 2ca1fd1d896f4276ba0b66e8042fc7f1
msgid "Failures happen, so completely preventing a ``split-brain`` event is not an absolute possibility. However, it is possible to alleviate some of the issues that crop up in any ``split-brain`` event scenarios by maxing out the heartbeat network bandwidth and optimizing transfer protocols."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_split_brain.rst:8
# 4d2471bd71ce498fa0e2a9a15dc2dfd4
msgid "|drbd| is a shared-nothing system. Data is replicated between hosts over a dedicated network link rather than stored on a central network-attached storage (NAS) or storage attached network (SAN) to which all hosts are connected. The most critical issue for storage in a |ha| topology is loss of or corruption of data. Maximizing the amount of data that can be passed over the wire while all systems are up and running correctly minimizes the chance that something will be lost or unrecoverable if a host goes down."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_split_brain.rst:10
# 3d1ee859841f46918abc9ae3d933345d
msgid "At any given time, only one |drbd| host has ``userland`` access to data, This host is referred to as the primary node. The other host runs the |drbd| daemon, but cannot mount the storage into the file system. The secondary node receives information from the primary node, and then replicates disk actions on its local storage copy (even if the partition looks like it doesn’t have a file system to which a ``mount`` command can be sent)."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_split_brain.rst:12
# f67dca95d7af4b308474184c1d81922c
msgid "The approach that |drbd| takes to ``split-brain`` event situations is to degrade all partners still alive to secondary status, and then wait for manual intervention. This is called auto-fencing, with a goal of minimizing the potential for damage to your data. When you lose one of the partners in a |ha| topology, a bit of manual intervention is required to ensure that the disks aren’t in a bad state and can be brought back up. These scenarios are discussed below, including suggestions for diagnosing and recovering from each scenario."
msgstr ""

#: ../source/server_high_availability.rst:37
# 7925e98b0ea74d8db8e56e386434b370
msgid "Split-brain Handlers"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_handlers.rst:4
# 3e292680b4a8452d9cd980c484adce40
msgid "|drbd| configuration allows for custom handlers when a ``split-brain`` event happens. The basic handler sends a notification email to a configurable email address so the issue can be investigated."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_handlers.rst:6
# d3317733a6844f329a9d423b60065d2b
msgid "The ``drbd.conf`` file that is used with |chef server oec| specifies other built-in actions that may be taken in certain fault scenarios:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_handlers.rst:14
# ce06e1c6fbd8427f86a1efb3113bf0f6
msgid "What this means:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_handlers.rst:16
# 2818c5a3736c4134a4bcc0c862a092c0
msgid "after-sb-0pri: A ``split-brain`` event has been detected and neither node is the primary node. The ``discard-younger-primary`` action will roll back any changes made on the last host that was the primary node."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_handlers.rst:17
# 1dd5b58227304d3cae6d4b75045d07f8
msgid "after-sb-1pri: A ``split-brain`` event has been detected and only one node believes that it was the primary node when the event happened. The ``discard-secondary`` action will continue operations on the primary node and will assume that the secondary node was lost."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_handlers.rst:18
# c6d11482985d4fde914aa33dc49d95c8
msgid "after-sb-2pri: A ``split-brain`` event has been detected and both nodes believed they were primary nodes. The ``call-pri-lost-after-sb`` action will attempt to apply the ``discard-younger-primary`` from the ``0pri`` configuration to determine which host should be the primary node. Once determined, the other host takes action to become the secondary node."
msgstr ""

#: ../source/server_high_availability.rst:41
# 3da583a41faa4265b7e6370d3470a9ea
msgid "Assumptions"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_assumptions.rst:4
# 5d56dae55815411f9c17b9511c867458
msgid "The following assumptions exist when |chef private| is deployed in a |ha| topology:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_assumptions.rst:6
# d4fb9a5113ad4305a887088ad558dbc4
msgid "The back-end processes run on two hosts: ``BE1`` and ``BE2``. ``BE1`` is the |drbd| primary and |chef server oec| master; ``BE2`` is the |drbd| secondary and the |chef server oec| backup"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_assumptions.rst:7
# 434d4e996f7346b89cc9be7f1609fe6c
msgid "The back-end uses |keepalived| and a dedicated network interface for heartbeat"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_assumptions.rst:8
# e5b2d24c3588439d961a08b61ea3d702
msgid "The back-end uses |drbd| for file redundancy"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_assumptions.rst:10
# 04fcdc9ccbb546808b97265509061f36
msgid "On each host, its own status is reported first, and then the status of its remote partner."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_assumptions.rst:12
# 6dec0213e2254ad8ac7f64d03ef0ad3a
msgid "When both the primary and secondary nodes are running and behaving as expected, the contents of ``/proc/drbd`` on the primary node will look similar to the following:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_assumptions.rst:21
# db4edf9f01f54fb49c4f10bcfd13f55c
msgid "On the secondary node, the status will look similar to the following:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_assumptions.rst:30
# 089a3362b46846deb9f1dfa43c520d1c
msgid "For information about the settings in this file, see the |drbd| website: http://www.drbd.org/users-guide/ch-admin.html."
msgstr ""

#: ../source/server_high_availability.rst:45
# 7e70d49f9eaa48b3aab721afd4f4fe48
msgid "Failure Scenarios"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario.rst:4
# b353dc35fe4e46509773d724b7ac3f80
msgid "The following four common scenarios are discussed:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario.rst:6
# ecd63062524e4bbdbc1a9e925b712a52
msgid "Back-end server #2 fails gracefully (all data is synced)"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario.rst:7
# 3ed22ecc1007421d923be00f52fd6700
msgid "Back-end server #2 hard fails badly (unsynced data)"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario.rst:8
# aca625fa1de14ec7bcf03b7c9d79f8ad
msgid "Back-end server #1 fails gracefully (all data is synced)"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario.rst:9
# 24b48c0af17e4b6fbf2f4f19eb7bfa11
msgid "Back-end server #1 hard fails badly (unsynced data)"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario.rst:10
# 694bb14aab154bc0828304d2096df89f
msgid "Both hosts are up as secondary, and |chef server oec| is unhappy"
msgstr ""

#: ../source/server_high_availability.rst:49
# e1e52f0d7f3443e99827ba6b893781d6
msgid "Scenarios 1 and 2"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_1and2.rst:4
# b96bbdcf47204436b3c26ef46055c3fe
msgid "When the acting backup server fails, |drbd| on the master will continue to function in primary mode, whether the |drbd| on the secondary was shut down gracefully or became unavailable unexpectedly. Verify that |drbd| is functioning by running ``drbdadm role pc0`` on the primary:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_1and2.rst:12
# 19f323483bde439c9a8d6d2b8aa5046e
msgid "You can see the full status by running cat ``/proc/drbd``:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_1and2.rst:21
# c695e362e10c44a7b767bd31c2edaef2
msgid "The disk partition is still mounted into the file system and can be used as normal."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_1and2.rst:23
# ff4cdcfd6e00420a91129e819a783570
msgid "When the secondary becomes available again, two things may happen:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_1and2.rst:25
# b2b8e25a0eef4df3b2e4ac7a2b935656
msgid "If the status of the secondary reports ``Inconsistent`` or ``UpToDate`` without manual intervention, all is well."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_1and2.rst:26
# 2497e5d2a7794b7f8627099fcbe837ac
msgid "If it remains ``DUnknown``, |drbd| on the secondary can be manually restarted and it will start to sync. The ``DUnknown`` status is the report which indicates that |drbd| sees no network connection to its partner."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_1and2.rst:28
# 86ddcf6475e64ae1803ac00d25085baf
msgid "The last field in the ``/prod/drbd`` file (``oos``) reports how far the primary is out of sync with its partner. If the secondary is down and there are a lot of writes on the primary, this number will increase. For example:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_1and2.rst:37
# 24133e3efc0547f391a918a0694fe0ac
msgid "When the disks return to a synced state, that field will return to ``0``. While the secondary is syncing, status about the syncing process will be shown for both hosts. For the secondary, something like the following:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_1and2.rst:47
# 330155e5e6e2496a9d644022ad145115
msgid "and for the primary, something like the following:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_1and2.rst:58
# cdd5d5531743440cb6848042fa68edbb
msgid "Eventually the hosts will quiesce and report ``ds:UpToDate/UpToDate``. Depending on how long the secondary was down, how much data was written to the primary in the interim, and the speed of the shared network, this process could be nearly instantaneous, or could take several minutes. Your |chef server oec| processes should not need to be manipulated in any way during this recovery."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_1and2.rst:60
# 07478db3bd27476a911e788828059b09
msgid "If the secondary host is lost completely, a new host can be installed in its place, the device built, and then |drbd| started. The new host will pair with the existing primary, sync data, and be ready to take over if necessary."
msgstr ""

#: ../source/server_high_availability.rst:53
# e6a94e42788449879a0db1399e0aae6c
msgid "Scenario 3"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_3.rst:4
# 6f2b950b256c401286c0eac6108466f7
msgid "Trouble starts when the |drbd| primary is the host that becomes unavailable. The |drbd| process on the secondary makes no assumptions about whether or not it should automatically take over, based on the split-brain configurations in the ``drbd.conf`` file."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_3.rst:6
# ca893cd3906d4a95bc2fd143035edc42
msgid "Basically, what this means is that when the primary becomes unavailable to the secondary without an explicit takeover being initiated, the secondary will assume that it itself is the wrong, ``split-brained`` host, and is the one unconnected and incorrect. It will take no automatic action."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_3.rst:8
# bc9a9b336114434b82a45b1c329b49a7
msgid "The status of the secondary will look something like the following:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_3.rst:17
# f4c7365d31ec4687932942cb0f91acf8
msgid "The ``ds:UpToDate/Unknown`` is important; it indicates that the secondary has all the data that was on the primary and won’t lose anything if it is promoted."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_3.rst:19
# e241c61052654e3b8bfeb2d76ece95b7
msgid "If it is verified that the primary host is going to be down for a while, the secondary can be promoted to primary:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_3.rst:25
# 2d2bace0845944c6bbc55abf5f1c2d74
msgid "at that point the status will change to something like the following:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_3.rst:34
# e536c0c404a9484f861b880044469fbd
msgid "Notice that ``ro`` is now ``ro:Primary/Unknown``. |chef server oec| can now be recovered by entering the following command:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_3.rst:40
# bdf2015c0858492a9cc3ec19d504f28b
msgid "This will start up the configured services and |chef server oec| will be master on this host."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_3.rst:42
# 695003905e4f4b12ae2838d1ddd44ac5
msgid "If the original primary can be brought back online, the cluster management script run by |keepalived| will try to do a |drbd| takeover, based on that host’s original primary |chef server oec| master status."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_3.rst:44
# 3e8d60904a3d4f88b31184f42e62e06d
msgid "The first thing it will do is attempt to promote itself to |drbd| primary, which will fail if the disk has been written to at all while this host was down, and |keepalived| will be unable to transition back to the original master. This leaves the pair of servers in a good state, with the second back-end box as the |drbd| primary |chef server oec| master."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_3.rst:46
# 93ccc9fcabe9400c88105bc3b18bd180
msgid "|drbd| on the first back-end server will sync to the second back-end server and will become the clean secondary |fqdn|."
msgstr ""

#: ../source/server_high_availability.rst:57
# c49a79427b294cc8ad40be6fcf163c10
msgid "Scenario 4"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_4.rst:4
# d75ca0efb0154b54bfb69257dc8f71dd
msgid "So far, the scenarios have not described any data loss. When the hosts in the High Availability pair are synced, either can be lost and the data will be safe."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_4.rst:6
# 90b9ee1aafc543eca9f39d9cab342954
msgid "If you get to a situation in which the primary host is lost and unrecoverable, but the last status of the |drbd| pair was reporting that the secondary node was in an ``Inconsistent`` state, it is very likely that some data will be lost. The |drbd| status on the remaining host will look something like the following:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_4.rst:15
# 9f6a53d83c0144f08f747d33ee55a739
msgid "As long as good source code management is practiced with cookbooks and other files in the |chef| repository, any missing bits can be re-uploaded after there is a working cluster. In some cases, newly-created users or organizations will need to be re-created. Other actions, such as |chef| runs and uploads may fail while the cluster is in an ``Inconsistent`` state, but will be fine after there is a working cluster."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_4.rst:17
# 3d51ae44193340f4bf9617485f01a325
msgid "When the primary back-end server has been lost while the secondary back-end server is in an ``Inconsistent`` state and it's not going to be back online quickly, the best thing to do is to provision another host to become the new |chef server oec| cluster partner for the secondary back-end server, and then build it out. If the new host has an IP address that is different from the primary back-end server, change the configuration on the secondary back-end server, and then reconfigure."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_4.rst:19
# bcf8e1bed1d5466187569aadb799a9c6
msgid "In this situation, |chef server oec| may be freaking out a bit, so turn off the daemons using the ``private-chef-ctl stop`` command."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_4.rst:21
# 8ea6c99028b84c8c912b162acf7c3775
msgid "Once the new host is identified and the |drbd| devices on that host are ready, bring up |drbd| and get it talking to the secondary back-end server. This secondary server should not want to be the primary server; it should be waiting for the old primary server to return. Start up |drbd| on the new host and verify that it is listening on the correct port and that the status in ``/proc/drbd`` is reporting that the host is up, but in the ``WFConnect: waiting for connection`` state."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_4.rst:23
# d79adee42f6a4547a67e9014b4053ee7
msgid "By the time you get the new node is up, the secondary back-end server may have taken itself into ``standalone`` mode, which means that it is no longer listening on the network port. In this situation, run the following commands to get the secondary back-end server to talk to the new node:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_4.rst:29
#: ../../includes_server_ha/includes_server_ha_scenario_5.rst:12
# ea378a547b2e43519920b3a5404f23df
# 6f20ea74c5fd48568edf198fe693cd32
msgid "and:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_4.rst:35
# 94007fec2a7d4ec9844081e446328f5e
msgid "At this point, the new host should be synchronizing with the secondary back-end server. The secondary back-end server will forget all about the data it was missing from the now-gone primary back-end server, and the process of bringing |chef server oec| back online can begin."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_4.rst:37
# 317d0de123d94f13b260fa4990434e8d
msgid "Running a fast network between the primary and secondary hosts, and keeping it full throttle for |drbd| transfers, will go a long way to mitigating the any damage that may be done in the event of a loss of the primary from an un-synced cluster."
msgstr ""

#: ../source/server_high_availability.rst:61
# 74cfd8a89fdb40c2936ce5efe9223027
msgid "Scenario 5"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_5.rst:4
# 5d0653e15d6f4c0fb654d5af1ad20bd6
msgid "Sometimes |drbd| hedges its bets, and puts both nodes in a pair into secondary mode. When this happens, you can look at the contents of ``/proc/drbd`` on both hosts and see if either of them is showing out of sync. If they are both ``oos:0``, just pick one and promote it to primary using the ``drbdadm primary pc0`` command. If one or both of the hosts is out of sync, choose the one with the lower amount of ``oos`` and promote it to primary."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_5.rst:6
# 1aa536cd0e6c4ec5831797287a7b7ec4
msgid "If the chosen node won’t promote, run the following commands on the other host to reset its disk state:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_5.rst:18
# c1102c0d93984433babef8a404f842f8
msgid "That will tell |drbd| to abandon what is on the node and start over, and should allow it to sync with the primary."
msgstr ""

