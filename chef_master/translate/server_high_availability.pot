# SOME DESCRIPTIVE TITLE.
# Copyright (C) This work is licensed under a Creative Commons Attribution 3.0 Unported License.
# This file is distributed under the same license as the Chef Docs package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Chef Docs \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2015-05-29 14:53-0700\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

#: ../source/server_high_availability.rst:8
# 43966f443633443e8ae7db548a7034f9
msgid "High Availability"
msgstr ""

#: ../../includes_server_ha/includes_server_ha.rst:4
# 5f4a1792846b4f30b73267e161479767
msgid "The |chef server| can operate in a high availability configuration that provides automated load balancing and failover for stateful components in the system architecture. This type of configuration typically splits the servers into two segments: front-end and back-end machines:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha.rst:8
# 27ce010446154c73bf1b0bb7b54a0b83
msgid "Front-end machines handle requests to the |api chef server| and access to the web user interface. Front-end machines should be load balanced and scaled horizontally by increasing the number of servers available to handle requests."
msgstr ""

#: ../../includes_server_ha/includes_server_ha.rst:10
# fc7ff1b9555545d29d6d9a1fe2a9ba66
msgid "Back-end machines handle data storage and retrieval, messaging and routing, analytics processing, and search. Back-end machines should be configured for failover using block level replication."
msgstr ""

#: ../source/server_high_availability.rst:12
# 9c6d8d1d7e7047fd82a6c8af411285d6
msgid "For |chef server| 12, the following high availability configurations are supported:"
msgstr ""

#: ../source/server_high_availability.rst:14
#: ../source/server_high_availability.rst:18
# 1c733163d3b049788cc04d616b12bdb4
# 58d0e27c967d4ef29aca192951cf8379
msgid "DRBD"
msgstr ""

#: ../source/server_high_availability.rst:15
#: ../source/server_high_availability.rst:58
# e2dd910af0644dd28e169cc972fca6d8
# b1b3c5a7f0b94a2a8c8977d497b72b74
msgid "AWS"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd.rst:4
# 99777277510947dbb15ef86d6980c3d5
msgid "|drbd| is a supported high availability configuration option for the |chef server|."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd.rst:8
# bca5d505fcc340bab46ef4bafd9f89c1
msgid "Front-end machines are scaled horizontally, and then load balanced using a hardware load balancer, |ssl| off-loading, and round-robin as the load balancing algorithm."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd.rst:10
# c062d279e91f45a5917fe05dff3b5cd7
msgid "Back-end machines are scaled vertically by adding memory, processing power, and faster disks to increase throughput, by adding faster disks and dedicated network interface cards to increase the reliability of |drbd| and the responsiveness of the |chef server|. Failover is achieved using:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd.rst:12
# 814ce615ce1e4358b59d4e73d15cd6ae
msgid "Asynchronous block level replication of logical volume managers, positioned between the two back-end machines"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd.rst:13
# 3832a1b7a2c34611ba481d2baf520608
msgid "A primary and backup cluster election using |vrrp| over unicast TCP/IP and |keepalived|"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd.rst:14
# 4eff83716189423bb903131bf3107c88
msgid "A virtual IP address to the primary |chef server| that is maintained based on the results of the election done by |keepalived|"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd.rst:16
# 98e1ca94831a4e39a9c6312ba3fca54d
msgid "When the primary |chef server| in the cluster fails, the |vrrp| heartbeat will stop. At this point, the backup server will begin transitioning to the primary state by:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd.rst:18
# 021e3d7b155e4c49935c93c9e5f08c36
msgid "Assigning the virtual IP address and sending a ``proxy-arp``; this step transitions the virtual IP address, which means traffic will flow to the back-end |chef server| while it makes the transition to becoming the primary |chef server|."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd.rst:19
# cc24734a63034f8980558b20f7936ea9
msgid "Attempting to take over as the primary |chef server| for the |drbd| device."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd.rst:20
# 467de54718754b6d8bdff6c0c2f71137
msgid "Starting all of the back-end services."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd.rst:22
# 6935146b6c02403b97ab72f0fbfa38e2
msgid "For more information about |drbd|, see http://www.drbd.org."
msgstr ""

#: ../source/server_high_availability.rst:22
# 486e9e6a2697417b95f0857c515432a7
msgid "Graceful Transitions"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_graceful_transitions.rst:4
# 104ae8d2708348f7a59d668337c2d975
msgid "The |keepalived| service manages the |vrrp| and cluster transitions. It should be running on both the primary and secondary servers. To transition from the primary to the secondary, simply run the following command on the primary |chef server|:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_graceful_transitions.rst:10
# 02700710743f49f39a744046233c4d7f
msgid "This will initiate a failover from the primary to the secondary |chef server| and will cause the current primary |chef server| to remove the virtual IP address, stop all services, unmount the |drbd| device, and then become the secondary |chef server| for the |drbd| device. Meanwhile, the secondary |chef server| will undergo a similar process, but become the primary |chef server|."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_graceful_transitions.rst:12
# 2fabefb17d954d0886bf55bcef5076d4
msgid "To view the progress of this transition, use the following command:"
msgstr ""

#: ../source/server_high_availability.rst:26
# a76df68523d348199e12a13582203122
msgid "Split Brains"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_split_brain.rst:4
# 00ee96fe82ca455f94028c468e5541fd
msgid "A ``split-brain`` event is a concept of clustered computing systems in which the cluster loses its heartbeat communication channel and becomes two unconnected pieces. Recovery from a ``split-brain`` event can be a complex issue and different clustering software packages use different methods."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_split_brain.rst:6
# 284f9fad0ace44d4821654ddea089f28
msgid "Failures happen, so completely preventing a ``split-brain`` event is not an absolute possibility. However, it is possible to alleviate some of the issues that crop up in any ``split-brain`` event scenarios by maxing out the heartbeat network bandwidth and optimizing transfer protocols."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_split_brain.rst:8
# a26588a1950649bd90a85cd54faa9c6e
msgid "|drbd| is a shared-nothing system. Data is replicated between hosts over a dedicated network link rather than stored on a central network-attached storage (NAS) or storage attached network (SAN) to which all hosts are connected. The most critical issue for storage in a |ha| topology is loss of or corruption of data. Maximizing the amount of data that can be passed over the wire while all systems are up and running correctly minimizes the chance that something will be lost or unrecoverable if a host goes down."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_split_brain.rst:10
# ab1bae242b274ada83f790c9be6d02a6
msgid "At any given time, only one |drbd| host has ``userland`` access to data, This host is referred to as the primary node. The other host runs the |drbd| daemon, but cannot mount the storage into the file system. The secondary node receives information from the primary node, and then replicates disk actions on its local storage copy (even if the partition looks like it doesn’t have a file system to which a ``mount`` command can be sent)."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_split_brain.rst:12
# 4719fc09498f44e4b73300b8b1688983
msgid "The approach that |drbd| takes to ``split-brain`` event situations is to degrade all partners still alive to secondary status, and then wait for manual intervention. This is called auto-fencing, with a goal of minimizing the potential for damage to your data. When you lose one of the partners in a |ha| topology, a bit of manual intervention is required to ensure that the disks aren’t in a bad state and can be brought back up. These scenarios are discussed below, including suggestions for diagnosing and recovering from each scenario."
msgstr ""

#: ../source/server_high_availability.rst:30
# b1995d3d4dc1483686ee38a6c9e4c039
msgid "Custom Handlers"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_handlers.rst:4
# f5746af27d9e47ac8120c46dde13a5f1
msgid "|drbd| configuration allows for custom handlers when a ``split-brain`` event happens. The basic handler sends a notification email to a configurable email address so the issue can be investigated."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_handlers.rst:6
# 45a1682e648241c3ade524d60a188d4a
msgid "The ``drbd.conf`` file that is used with the |chef server| specifies other built-in actions that may be taken in certain fault scenarios:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_handlers.rst:14
# 78ddd98793b643cc8918f4b4d359d6d7
msgid "What this means:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_handlers.rst:16
# 91178956b4504b7fb0bf35dc994ff926
msgid "after-sb-0pri: A ``split-brain`` event has been detected and neither node is the primary node. The ``discard-younger-primary`` action will roll back any changes made on the last host that was the primary node."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_handlers.rst:17
# 0643f38662f84966b470d15ab59e69e3
msgid "after-sb-1pri: A ``split-brain`` event has been detected and only one node believes that it was the primary node when the event happened. The ``discard-secondary`` action will continue operations on the primary node and will assume that the secondary node was lost."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_handlers.rst:18
# 409accbc4a854d7bb5e473bdd9bb65e0
msgid "after-sb-2pri: A ``split-brain`` event has been detected and both nodes believed they were primary nodes. The ``call-pri-lost-after-sb`` action will attempt to apply the ``discard-younger-primary`` from the ``0pri`` configuration to determine which host should be the primary node. Once determined, the other host takes action to become the secondary node."
msgstr ""

#: ../source/server_high_availability.rst:34
# 237183b8a2374e379c430bc03f5a23d9
msgid "Assumptions"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_assumptions.rst:4
# 5ceed8430f654ef48daac302e4211b38
msgid "The following assumptions exist when the |chef server| is deployed in a |ha| topology:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_assumptions.rst:6
# 530f6880f0f14f28a3a55d77db0cf001
msgid "The back-end processes run on two hosts: ``BE1`` and ``BE2``. ``BE1`` is the |drbd| primary and the master |chef server|; ``BE2`` is the |drbd| secondary and the |chef server| backup"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_assumptions.rst:7
# 21ba20b012e6455aa6f525d2c612ec62
msgid "The back-end uses |keepalived| and a dedicated network interface for heartbeat"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_assumptions.rst:8
# 784d38177a1f4cdd8eecad14704d6245
msgid "The back-end uses |drbd| for file redundancy"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_assumptions.rst:10
# defde9b5e15c4752b4ee248df3852412
msgid "On each host, its own status is reported first, and then the status of its remote partner."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_assumptions.rst:12
# ef22802aac6141b1a088af860ecd2fd2
msgid "When both the primary and secondary nodes are running and behaving as expected, the contents of ``/proc/drbd`` on the primary node will look similar to the following:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_assumptions.rst:21
# cafa872fd60d469ba6fa89743790033c
msgid "On the secondary node, the status will look similar to the following:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_assumptions.rst:30
# 7a9de198da0b4e47b63a3269723b799a
msgid "For information about the settings in this file, see the |drbd| website: http://www.drbd.org/users-guide/ch-admin.html."
msgstr ""

#: ../source/server_high_availability.rst:38
# 2d1ed20fc991431db745fdac0754f1d4
msgid "Failure Scenarios"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario.rst:4
# 3f51cf57f5ac417da35d04983b49f93b
msgid "The following four common scenarios are discussed:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario.rst:6
# 9eb9d8eb756e408c95f87bd0be2fdd3e
msgid "Back-end server #2 fails gracefully (all data is synced)"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario.rst:7
# 86cf63c7df0648e0be9d65f845bdd3e8
msgid "Back-end server #2 hard fails badly (unsynced data)"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario.rst:8
# 66ee684061ac45e19cb2f85bd0723fb8
msgid "Back-end server #1 fails gracefully (all data is synced)"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario.rst:9
# 9e27b847d86c45158de59b01dedd492d
msgid "Back-end server #1 hard fails badly (unsynced data)"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario.rst:10
# 255a588c0d8140e4beea5a66bff96528
msgid "Both hosts are up as secondary, and the |chef server| is unhappy"
msgstr ""

#: ../source/server_high_availability.rst:42
# de6cf68c1d104a179a9c942fb98cb8f5
msgid "Scenarios 1 and 2"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario_1and2.rst:4
# 4a94a40deb8744d1847c4662540fdb4c
msgid "When the acting backup server fails, |drbd| on the master will continue to function in primary mode, whether the |drbd| on the secondary was shut down gracefully or became unavailable unexpectedly. Verify that |drbd| is functioning by running ``drbdadm role pc0`` on the primary:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario_1and2.rst:12
# 5a73b1c28dc64bdc87cf7d795198b97f
msgid "You can see the full status by running cat ``/proc/drbd``:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario_1and2.rst:21
# caa9d24e5cf84ce3901ad68a8a80faa5
msgid "The disk partition is still mounted into the file system and can be used as normal."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario_1and2.rst:23
# b637ab1b9ee24a93aa43d5df74f59b42
msgid "When the secondary becomes available again, two things may happen:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario_1and2.rst:25
# e89b0c95c1024abdabf29d7fbffd8cb0
msgid "If the status of the secondary reports ``Inconsistent`` or ``UpToDate`` without manual intervention, all is well."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario_1and2.rst:26
# b2d0f5807f1a4913a9ff76f86b47a094
msgid "If it remains ``DUnknown``, |drbd| on the secondary can be manually restarted and it will start to sync. The ``DUnknown`` status is the report which indicates that |drbd| sees no network connection to its partner."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario_1and2.rst:28
# 7ba6f3b8b3a84a84a71620b0260b64be
msgid "The last field in the ``/prod/drbd`` file (``oos``) reports how far the primary is out of sync with its partner. If the secondary is down and there are a lot of writes on the primary, this number will increase. For example:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario_1and2.rst:37
# 2b9f93b71b1746a884b9d13c12d96e6e
msgid "When the disks return to a synced state, that field will return to ``0``. While the secondary is syncing, status about the syncing process will be shown for both hosts. For the secondary, something like the following:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario_1and2.rst:47
# 775af3a603c648829a2b121aeb544e9a
msgid "and for the primary, something like the following:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario_1and2.rst:58
# a162aced62c246ecaf1f711982a9032d
msgid "Eventually the hosts will quiesce and report ``ds:UpToDate/UpToDate``. Depending on how long the secondary was down, how much data was written to the primary in the interim, and the speed of the shared network, this process could be nearly instantaneous, or could take several minutes. The processes used to manage the |chef server| should not require manipulation in any way during this recovery."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario_1and2.rst:60
# 9ff37a5c324e43179b341618043be34f
msgid "If the secondary host is lost completely, a new host can be installed in its place, the device built, and then |drbd| started. The new host will pair with the existing primary, sync data, and be ready to take over if necessary."
msgstr ""

#: ../source/server_high_availability.rst:46
# 4d5e466fcef04a5295d16295c03667d4
msgid "Scenario 3"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario_3.rst:4
# a9c9bfb0aff64822bbaf6730cacdaf30
msgid "Trouble starts when the |drbd| primary is the host that becomes unavailable. The |drbd| process on the secondary makes no assumptions about whether or not it should automatically take over, based on the split-brain configurations in the ``drbd.conf`` file."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario_3.rst:6
# b6503f13e04e41fd9353cf11ff9c49d9
msgid "Basically, what this means is that when the primary becomes unavailable to the secondary without an explicit takeover being initiated, the secondary will assume that it itself is the wrong, ``split-brained`` host, and is the one unconnected and incorrect. It will take no automatic action."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario_3.rst:8
# 104cd8c6cc464081b8aa962de82d8a5f
msgid "The status of the secondary will look something like the following:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario_3.rst:17
# 3cadc328d5c747c2a0dd0c7906458f28
msgid "The ``ds:UpToDate/Unknown`` is important; it indicates that the secondary has all the data that was on the primary and won’t lose anything if it is promoted."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario_3.rst:19
# 18216707290a493483f4bb56adb12499
msgid "If it is verified that the primary host is going to be down for a while, the secondary can be promoted to primary:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario_3.rst:25
# 602ce726f7e040f891977bae87399e71
msgid "at that point the status will change to something like the following:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario_3.rst:34
# 05fc65e99f8e4bdd8857efed4e71ecd6
msgid "Notice that ``ro`` is now ``ro:Primary/Unknown``. The |chef server| can now be recovered by entering the following command:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario_3.rst:40
# e669d954005f439799ed673e09bf4973
msgid "This will start up the configured services and the |chef server| will be master on this host."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario_3.rst:42
# 9a86d7b43e9546cfa0e739edcd7f3d4c
msgid "If the original primary can be brought back online, the cluster management script run by |keepalived| will try to do a |drbd| takeover, based on that host’s original primary |chef server| master status."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario_3.rst:44
# e306f09b61984cb0bde60c1f985fe5ca
msgid "The first thing it will do is attempt to promote itself to |drbd| primary, which will fail if the disk has been written to at all while this host was down, and |keepalived| will be unable to transition back to the original master. This leaves the pair of servers in a good state, with the second back-end box as the |drbd| primary |chef server| master."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario_3.rst:46
# e87104fd257647d3950e680dbf506ebf
msgid "|drbd| on the first back-end server will sync to the second back-end server and will become the clean secondary |fqdn|."
msgstr ""

#: ../source/server_high_availability.rst:50
# 750e8a762732414393829b4c4af0911a
msgid "Scenario 4"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario_4.rst:4
# f2f692a7311e4e8882c26da9c3bea46e
msgid "So far, the scenarios have not described any data loss. When the hosts in the high availability pair are synced, either can be lost and the data will be safe."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario_4.rst:6
# 429e85b0d553494cafcb8b96a3a3f1a0
msgid "If you get to a situation in which the primary host is lost and unrecoverable, but the last status of the |drbd| pair was reporting that the secondary node was in an ``Inconsistent`` state, it is very likely that some data will be lost. The |drbd| status on the remaining host will look something like the following:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario_4.rst:15
# d900e6922608452dbfa42038937436c5
msgid "As long as good source code management is practiced with cookbooks and other files in the |chef repo|, any missing bits can be re-uploaded after there is a working cluster. In some cases, newly-created users or organizations will need to be re-created. Other actions, such as |chef client| runs and uploads may fail while the cluster is in an ``Inconsistent`` state, but will be fine after there is a working cluster."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario_4.rst:17
# 06eba5a8586042a19b231939a21feb2e
msgid "When the primary back-end server has been lost while the secondary back-end server is in an ``Inconsistent`` state and it's not going to be back online quickly, the best thing to do is to provision another host to become the new |chef server| cluster partner for the secondary back-end server, and then build it out. If the new host has an IP address that is different from the primary back-end server, change the configuration on the secondary back-end server, and then reconfigure."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario_4.rst:19
# 16a681f7662e4c7488dad24ef60a1b1c
msgid "In this situation, the |chef server| may be freaking out a bit, so turn off the daemons using the ``chef-server-ctl stop`` command."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario_4.rst:21
# 1539b8a559264341bbc95ec3a6720072
msgid "Once the new host is identified and the |drbd| devices on that host are ready, bring up |drbd| and get it talking to the secondary back-end server. This secondary server should not want to be the primary server; it should be waiting for the old primary server to return. Start up |drbd| on the new host and verify that it is listening on the correct port and that the status in ``/proc/drbd`` is reporting that the host is up, but in the ``WFConnect: waiting for connection`` state."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario_4.rst:23
# a276ff4010d043798614a6837056cba2
msgid "By the time you get the new node is up, the secondary back-end server may have taken itself into ``standalone`` mode, which means that it is no longer listening on the network port. In this situation, run the following commands to get the secondary back-end server to talk to the new node:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario_4.rst:29
#: ../../includes_server_ha/includes_server_ha_drbd_scenario_5.rst:12
# d05d9f975834422f825b7c6ddc4e4bc5
# f4fb1751a37b47a78dfe5265b2abe706
msgid "and:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario_4.rst:35
# a3f4df340a0a4859a269a493ead53184
msgid "At this point, the new host should be synchronizing with the secondary back-end server. The secondary back-end server will forget all about the data it was missing from the now-gone primary back-end server, and the process of bringing the |chef server| back online can begin."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario_4.rst:37
# 5365795572304736b79d0fa94a525647
msgid "Running a fast network between the primary and secondary hosts, and keeping it full throttle for |drbd| transfers, will go a long way to mitigating the any damage that may be done in the event of a loss of the primary from an un-synced cluster."
msgstr ""

#: ../source/server_high_availability.rst:54
# 0af316aec2fb4225b114f82d9d2b5cb6
msgid "Scenario 5"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario_5.rst:4
# 4f13710acfce4f46bd1e28172175ed03
msgid "Sometimes |drbd| hedges its bets, and puts both nodes in a pair into secondary mode. When this happens, you can look at the contents of ``/proc/drbd`` on both hosts and see if either of them is showing out of sync. If they are both ``oos:0``, just pick one and promote it to primary using the ``drbdadm primary pc0`` command. If one or both of the hosts is out of sync, choose the one with the lower amount of ``oos`` and promote it to primary."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario_5.rst:6
# b81b9d027d164e4e97539717c5964ac6
msgid "If the chosen node won’t promote, run the following commands on the other host to reset its disk state:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_scenario_5.rst:18
# 83bd8923d91941cbb388613d5f8714aa
msgid "That will tell |drbd| to abandon what is on the node and start over, and should allow it to sync with the primary."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_aws.rst:4
# fbbc4965384845bfb38e319f72d07ffa
msgid "|amazon aws| is a supported high availability configuration option for the |chef server|."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_aws.rst:8
# 712dfe5729074547bc654f3088ff2c4f
msgid "Machines are stored as |amazon ebs| volumes. A passive node monitors the availabilty of the active node, and will take over if required."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_aws.rst:10
# 79443fc0e0ad44838c023365e6596b65
msgid "For more information about |amazon ebs|, see http://aws.amazon.com/ebs/."
msgstr ""

#: ../source/server_high_availability.rst:61
# bd115cf8889646cebca71ecb0e6cf371
msgid "View the topic :doc:`High Availability: AWS </install_server_ha_aws>` for more information about how to set up the |chef server| for high availability in |amazon aws|."
msgstr ""

#: ../../includes_chef/includes_chef_subscriptions.rst:4
# 14df6d1766484e4cba89474493132bbb
msgid "This is a premium feature of |chef|. Access to premium features is free (up to 25 nodes) when the |chef server| is installed on-premises. For higher node counts, access is `available via subscription <https://www.chef.io/chef/#plans-and-pricing>`_. Premium features are installed `from the command line <http://docs.chef.io/ctl_chef_server.html#install>`_."
msgstr ""

#: ../source/server_high_availability.rst:66
# 8d6af83abb3f4bfbb95c71d13e0acf99
msgid "Check HA Status"
msgstr ""

#: ../../includes_api_chef_server/includes_api_chef_server_endpoint_status.rst:4
# c31c8434ec054b41ad6e51e7b5df6f62
msgid "The ``/_status`` endpoint can be used to check the status of communications between the front and back end servers. This endpoint is located at ``/_status`` on the front end servers."
msgstr ""

#: ../../includes_api_chef_server/includes_api_chef_server_endpoint_status.rst:6
# 717824b0850543d0be398a7602bf0f8d
msgid "**Request**"
msgstr ""

#: ../../includes_api_chef_server/includes_api_chef_server_endpoint_status.rst:12
# 2e7ec37d2dfd4d49870286d90fc3d093
msgid "This method has no request body."
msgstr ""

#: ../../includes_api_chef_server/includes_api_chef_server_endpoint_status.rst:14
# cdb4ef55439a44b3905f4dcc0abb88c2
msgid "**Response**"
msgstr ""

#: ../../includes_api_chef_server/includes_api_chef_server_endpoint_status.rst:16
# 91344cd85b9f44c4af6361b2371d492c
msgid "The response will return something like the following:"
msgstr ""

#: ../../includes_api_chef_server/includes_api_chef_server_endpoint_status.rst:30
# cc724c56b0bb4af4bfd6e948e04dacef
msgid "**Response Codes**"
msgstr ""

#: ../../includes_api_chef_server/includes_api_chef_server_endpoint_status.rst:36
# 9f6afe54c46e4cf386db5e677998ffb4
msgid "Response Code"
msgstr ""

#: ../../includes_api_chef_server/includes_api_chef_server_endpoint_status.rst:37
# 16fbcf23441a47f2a18e0d82a7fee96c
msgid "Description"
msgstr ""

#: ../../includes_api_chef_server/includes_api_chef_server_endpoint_status.rst:38
# f30d6ac9b46f40d2b8bf85ae46c54d75
msgid "``200``"
msgstr ""

#: ../../includes_api_chef_server/includes_api_chef_server_endpoint_status.rst:39
# 5b3d27051b3d462fb329489fe400b00d
msgid "All communications are OK."
msgstr ""

#: ../../includes_api_chef_server/includes_api_chef_server_endpoint_status.rst:40
# de28511dfc3b4ff78ae36a08b90c8b58
msgid "``500``"
msgstr ""

#: ../../includes_api_chef_server/includes_api_chef_server_endpoint_status.rst:41
# 3352bbabf91a4cdfa4233f6c1a01eb42
msgid "One (or more) services are down. For example:"
msgstr ""

