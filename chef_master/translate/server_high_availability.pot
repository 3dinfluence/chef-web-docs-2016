# SOME DESCRIPTIVE TITLE.
# Copyright (C) This work is licensed under a Creative Commons Attribution 3.0 Unported License.
# This file is distributed under the same license as the Chef Docs package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Chef Docs \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2014-02-06 22:47\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

#: ../source/server_high_availability.rst:8
# 3fd25657fa394332a2f2fcec967432aa
msgid "High Availability"
msgstr ""

#: ../../includes_server_ha/includes_server_ha.rst:4
# 6a4e88b8a0664973b7632153ab4e73f4
msgid "|chef server oec| can operate in a high availability configuration that provides automated failover for stateful components in the system architecture. This configuration splits servers into two segments: front-end and back-end servers. The front-end servers handle requests to the user interface and requests that use the |api chef server|. The back-end servers handle data storage and retrieval, which consists of:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha.rst:6
# a3a50bf0339f467abe57fb47c4c2d0d8
msgid "|couch db|"
msgstr ""

#: ../../includes_server_ha/includes_server_ha.rst:7
# 5f513836871e4e37b15d5037725ecc08
msgid "|postgresql|"
msgstr ""

#: ../../includes_server_ha/includes_server_ha.rst:8
# 84f136656ade46b080d43c56f3f57cbc
msgid "|opscode solr|"
msgstr ""

#: ../../includes_server_ha/includes_server_ha.rst:9
# d5d0b153254c4078bbbbf2fc86cdc675
msgid "|rabbitmq|"
msgstr ""

#: ../../includes_server_ha/includes_server_ha.rst:10
# b1e82f8519544dbb8faa5a250b3b737f
msgid "|redis|"
msgstr ""

#: ../../includes_server_ha/includes_server_ha.rst:11
# e97eabd863cc4410b2f67d016d2440d2
msgid "Cookbook data"
msgstr ""

#: ../../includes_server_ha/includes_server_ha.rst:13
# 1ddd48a2e44341aea58328382c5e492c
msgid "Failover on the back-end servers is achieved using the following:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha.rst:15
# 3333e18e75f84473bac4234c6584c27f
msgid "Asynchronous block level replication of logical volume managers using |drbd|, positioned between two back-end servers"
msgstr ""

#: ../../includes_server_ha/includes_server_ha.rst:16
# f728056dd5a04e22b835959c14466ce4
msgid "A primary and backup cluster election using |vrrp| over unicast TCP/IP and |keepalived|"
msgstr ""

#: ../../includes_server_ha/includes_server_ha.rst:17
# e0852e64a8f04954bd39933b329f2512
msgid "A virtual IP address to the primary server, maintained based on the results of the election done by |keepalived|"
msgstr ""

#: ../../includes_server_ha/includes_server_ha.rst:21
# b6c04eb922044617a5fb1b4f2da54de8
msgid "The front-end servers require load-balancers. |company_name| recommends:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha.rst:23
# 3033cb16dc2c4262800bfe9595d574af
msgid "Hardware load-balancers (such as |f5| or |netscalar|)"
msgstr ""

#: ../../includes_server_ha/includes_server_ha.rst:24
# 60fc2ed59a3747268151e08b9f02d8e8
msgid "|ssl| off-loading"
msgstr ""

#: ../../includes_server_ha/includes_server_ha.rst:25
# 7e06f4584d3e41c6b729a0d7a7b3f8d1
msgid "Round-robin as the load-balancing algorithm"
msgstr ""

#: ../source/server_high_availability.rst:13
# 16edbb78fde74018a138060380412b9c
msgid "Scalability"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scalability.rst:4
# 477c778cb2984d29bb750782291ea4e4
msgid "Scalability for front-end servers is achieved by horizontally scaling the number of servers."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scalability.rst:6
# b4a6e1411fed4fd9a9d18b4b84da2911
msgid "Scalability for back-end servers is achieved by vertically scaling the servers. For example, adding memory, CPU, and faster disks will all increase throughput from the back-end servers. Faster disks, and dedicated network interface cards will all increase the reliability of |drbd| and the responsiveness of |chef server oec|."
msgstr ""

#: ../source/server_high_availability.rst:17
# d33f9d9dceb44f9eba16f8d0a40ba945
msgid "Failover and Recovery"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_failover.rst:4
# 68535d566d214fcc8da79c026d29e9c6
msgid "When the primary server in the cluster fails, the |vrrp| heartbeat will stop. At this point the backup server will begin transitioning to the primary state, which involves:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_failover.rst:6
# cd196e0359394a67a3f9b3426fea1aa9
msgid "Assigning the virtual IP address and sending a ``proxy-arp``"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_failover.rst:7
# 70bb989d94bb44d8be171db0d0c5f7ef
msgid "Attempting to take-over as the primary server for the |drbd| device"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_failover.rst:8
# 44762177a11f4042a9506f50d7848702
msgid "Starting all of the back-end services"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_failover.rst:10
# 4bf0566b523442728d780e0916bd7b5f
msgid "The first step is transitioning the virtual IP address, which means that traffic will flow to the backup server while it makes the transition to being the primary server."
msgstr ""

#: ../source/server_high_availability.rst:21
# 8b1e95071c5c4dacab701dd75457281e
msgid "Graceful Transitions"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_transitions.rst:4
# 4602939062144db68d28c90674b58afa
msgid "The |keepalived| service manages the |vrrp| and cluster transitions. It should be running on both the primary and secondary servers. To transition from the primary to the secondary, simply run the following on the primary:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_transitions.rst:10
# a8243b3ae8db43478149293642f663e8
msgid "which will initiate a failover from the primary to the secondary. This will cause the current primary to:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_transitions.rst:12
# cea07f2eb0414fa9ac4140a3ddef7cdb
msgid "Remove the virtual IP address."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_transitions.rst:13
# c56531b5041c4da19425c1fa2694d829
msgid "Stop the services."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_transitions.rst:14
# cd09671a53f44c548fb40d74d745ef3f
msgid "Unmount the |drbd| device."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_transitions.rst:15
# 0512cb6445c64790af5b8372cf779c0e
msgid "Becoming secondary for the |drbd| device."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_transitions.rst:17
# c17a0fc9a2574b6eaea78398ee33fcb4
msgid "Meanwhile, the backup will be undergoing the same steps as listed above. Use the ``ha-status`` option to view the progress:"
msgstr ""

#: ../source/server_high_availability.rst:25
# e24d92c7b19940a5aad615be46d2edc4
msgid "Status"
msgstr ""

#: ../../includes_api_chef_server/includes_api_chef_server_endpoint_status.rst:4
# 3c0e34db84e9441a9f8dfc132de5559b
msgid "The ``/_status`` endpoint can be used to check the status of communications between the front and back end servers. This endpoint is located at ``/_status`` on the front end servers."
msgstr ""

#: ../../includes_api_chef_server/includes_api_chef_server_endpoint_status.rst:6
# 198c7897759a44e999d076289941703d
msgid "**Request**"
msgstr ""

#: ../../includes_api_chef_server/includes_api_chef_server_endpoint_status.rst:12
# 06b102f5b74c4142a708457c257adc85
msgid "This method has no request body."
msgstr ""

#: ../../includes_api_chef_server/includes_api_chef_server_endpoint_status.rst:14
# 8a75720dacbc4d1ba88490189de8719a
msgid "**Response**"
msgstr ""

#: ../../includes_api_chef_server/includes_api_chef_server_endpoint_status.rst:16
# 1b2509c7882f4dd7bb0d76f9fb503602
msgid "The response will return something like the following:"
msgstr ""

#: ../../includes_api_chef_server/includes_api_chef_server_endpoint_status.rst:31
# 7d600edf5b1b453d8700c3bbf88c6084
msgid "**Response Codes**"
msgstr ""

#: ../../includes_api_chef_server/includes_api_chef_server_endpoint_status.rst:37
# ae100a5e997f430cb0ea63e360633d39
msgid "Response Code"
msgstr ""

#: ../../includes_api_chef_server/includes_api_chef_server_endpoint_status.rst:38
# 180ce2bc91274074ad7880d3b2934e44
msgid "Description"
msgstr ""

#: ../../includes_api_chef_server/includes_api_chef_server_endpoint_status.rst:39
# 48bae8af7bdb43a5a6089b520cced645
msgid "``200``"
msgstr ""

#: ../../includes_api_chef_server/includes_api_chef_server_endpoint_status.rst:40
# 60ea0c79ab4e4d37a1386344ff7d07e3
msgid "All communications are OK."
msgstr ""

#: ../../includes_api_chef_server/includes_api_chef_server_endpoint_status.rst:41
# 5e604bca2fd4491e8994e6f28f7669d4
msgid "``500``"
msgstr ""

#: ../../includes_api_chef_server/includes_api_chef_server_endpoint_status.rst:42
# db38a9b3da2a4294987d81c5832f32fb
msgid "One (or more) services are down. For example:"
msgstr ""

#: ../source/server_high_availability.rst:29
# 10879e672ff7403789a39f6b8c7b656c
msgid "DRBD"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd.rst:4
# 53ff4a66b02147a9a11dd386b362732c
msgid "|drbd| is used as part of a |ha| topology for |chef server oec|. More information about |drbd| is available from their website: http://www.drbd.org."
msgstr ""

#: ../source/server_high_availability.rst:33
# a5f71b8ed293493da82f1191b8138daf
msgid "Split Brains"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_split_brain.rst:4
# 1addc1e477f54cb7afd53fd3016d05c4
msgid "A ``split-brain`` event is a concept of clustered computing systems in which the cluster loses its heartbeat communication channel and becomes two unconnected pieces. Recovery from a ``split-brain`` event can be a complex issue and different clustering software packages use different methods."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_split_brain.rst:6
# ebc67882966848c3b2bcd25a9a8895a9
msgid "Failures happen, so completely preventing a ``split-brain`` event is not an absolute possibility. However, it is possible to alleviate some of the issues that crop up in any ``split-brain`` event scenarios by maxing out the heartbeat network bandwidth and optimizing transfer protocols."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_split_brain.rst:8
# 9ca3294a15824c4fa80e58c3ae138459
msgid "|drbd| is a shared-nothing system. Data is replicated between hosts over a dedicated network link rather than stored on a central network-attached storage (NAS) or storage attached network (SAN) to which all hosts are connected. The most critical issue for storage in a |ha| topology is loss of or corruption of data. Maximizing the amount of data that can be passed over the wire while all systems are up and running correctly minimizes the chance that something will be lost or unrecoverable if a host goes down."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_split_brain.rst:10
# 7341c33f2ca041f786a685c7c3ec85c0
msgid "At any given time, only one |drbd| host has ``userland`` access to data, This host is referred to as the primary node. The other host runs the |drbd| daemon, but cannot mount the storage into the file system. The secondary node receives information from the primary node, and then replicates disk actions on its local storage copy (even if the partition looks like it doesn’t have a file system to which a ``mount`` command can be sent)."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_split_brain.rst:12
# d1d48db7870c44bc8f8994cf0a5fbffd
msgid "The approach that |drbd| takes to ``split-brain`` event situations is to degrade all partners still alive to secondary status, and then wait for manual intervention. This is called auto-fencing, with a goal of minimizing the potential for damage to your data. When you lose one of the partners in a |ha| topology, a bit of manual intervention is required to ensure that the disks aren’t in a bad state and can be brought back up. These scenarios are discussed below, including suggestions for diagnosing and recovering from each scenario."
msgstr ""

#: ../source/server_high_availability.rst:37
# bba1c19550e542a1995a61698a4fcb1a
msgid "Split-brain Handlers"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_handlers.rst:4
# dbc637c7da50406682dcaaa968b38a0b
msgid "|drbd| configuration allows for custom handlers when a ``split-brain`` event happens. The basic handler sends a notification email to a configurable email address so the issue can be investigated."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_handlers.rst:6
# d8c9fbdf1b634971ae1520f7af1e0dc6
msgid "The ``drbd.conf`` file that is used with |chef server oec| specifies other built-in actions that may be taken in certain fault scenarios:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_handlers.rst:14
# 32d0a59983d4496696855b75e275d533
msgid "What this means:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_handlers.rst:16
# 56693a0cbe1b4673a7e01c1757d21eec
msgid "after-sb-0pri: A ``split-brain`` event has been detected and neither node is the primary node. The ``discard-younger-primary`` action will roll back any changes made on the last host that was the primary node."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_handlers.rst:17
# d8434beb9a924e73a9e56988a2c6e818
msgid "after-sb-1pri: A ``split-brain`` event has been detected and only one node believes that it was the primary node when the event happened. The ``discard-secondary`` action will continue operations on the primary node and will assume that the secondary node was lost."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_handlers.rst:18
# 5ec62dcc35c74578bcc7bd2f117088c8
msgid "after-sb-2pri: A ``split-brain`` event has been detected and both nodes believed they were primary nodes. The ``call-pri-lost-after-sb`` action will attempt to apply the ``discard-younger-primary`` from the ``0pri`` configuration to determine which host should be the primary node. Once determined, the other host takes action to become the secondary node."
msgstr ""

#: ../source/server_high_availability.rst:41
# 7a557ed9cb924e32ab07a682da2cce52
msgid "Assumptions"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_assumptions.rst:4
# 6350bdb4567b489ba2cadd80092c1c5a
msgid "The following assumptions exist when |chef private| is deployed in a |ha| topology:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_assumptions.rst:6
# 62f1bb36bfc643469411daab668ce97d
msgid "The back-end processes run on two hosts: ``BE1`` and ``BE2``. ``BE1`` is the |drbd| primary and |chef server oec| master; ``BE2`` is the |drbd| secondary and the |chef server oec| backup"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_assumptions.rst:7
# c5beccdbbd33481394490964ad90e99f
msgid "The back-end uses |keepalived| and a dedicated network interface for heartbeat"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_assumptions.rst:8
# c11e3dcc254f499398ba2b9428b23684
msgid "The back-end uses |drbd| for file redundancy"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_assumptions.rst:10
# 689ca615c8dd4fceabf93aa36ba4ca1f
msgid "On each host, its own status is reported first, and then the status of its remote partner."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_assumptions.rst:12
# e38d86721377482fbb015e390b977cef
msgid "When both the primary and secondary nodes are running and behaving as expected, the contents of ``/proc/drbd`` on the primary node will look similar to the following:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_assumptions.rst:21
# 9163b1d64ca5404eb661671a0716e1e2
msgid "On the secondary node, the status will look similar to the following:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_assumptions.rst:30
# 22a6ff5e6e1d4f36bacbc691ab6f6444
msgid "For information about the settings in this file, see the |drbd| website: http://www.drbd.org/users-guide/ch-admin.html."
msgstr ""

#: ../source/server_high_availability.rst:45
# d4f2bc96cfc34eff892438f3be008ab7
msgid "Failure Scenarios"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario.rst:4
# 3f3854b011564d6f94eb774ea012bd82
msgid "The following four common scenarios are discussed:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario.rst:6
# 8f5ff0f61c15487d92f8f14e9c91388a
msgid "Back-end server #2 fails gracefully (all data is synced)"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario.rst:7
# 3676a439ad2e4dba97ac1649071093b8
msgid "Back-end server #2 hard fails badly (unsynced data)"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario.rst:8
# 9c63f21fa5124896ac0c1eb4c64b8daf
msgid "Back-end server #1 fails gracefully (all data is synced)"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario.rst:9
# bd536786163b485db674c708599997ec
msgid "Back-end server #1 hard fails badly (unsynced data)"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario.rst:10
# 35281dd4311d49578b1dd82412ab7f6a
msgid "Both hosts are up as secondary, and |chef server oec| is unhappy"
msgstr ""

#: ../source/server_high_availability.rst:49
# 6ccebd10fe074b859ea03feb40a08b8c
msgid "Scenarios 1 and 2"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_1and2.rst:4
# 7931bfb3269847f69178c92c17a6c183
msgid "When the acting backup server fails, |drbd| on the master will continue to function in primary mode, whether the |drbd| on the secondary was shut down gracefully or became unavailable unexpectedly. Verify that |drbd| is functioning by running ``drbdadm role pc0`` on the primary:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_1and2.rst:12
# d398acded93a4d15a432f779102b5824
msgid "You can see the full status by running cat ``/proc/drbd``:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_1and2.rst:21
# 9d37a6b14d1846359de6d426da7673aa
msgid "The disk partition is still mounted into the file system and can be used as normal."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_1and2.rst:23
# e1f33e4e25114e72bbb96dd6299815b7
msgid "When the secondary becomes available again, two things may happen:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_1and2.rst:25
# 9bad379eedf4437386adc848f1948ec4
msgid "If the status of the secondary reports ``Inconsistent`` or ``UpToDate`` without manual intervention, all is well."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_1and2.rst:26
# cc03dfc0490e439a80f62b539c5348c3
msgid "If it remains ``DUnknown``, |drbd| on the secondary can be manually restarted and it will start to sync. The ``DUnknown`` status is the report which indicates that |drbd| sees no network connection to its partner."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_1and2.rst:28
# d0a1f126b6014b8a88562ef2eace7590
msgid "The last field in the ``/prod/drbd`` file (``oos``) reports how far the primary is out of sync with its partner. If the secondary is down and there are a lot of writes on the primary, this number will increase. For example:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_1and2.rst:37
# c81fc3a093544b1bb9da6492d2b80271
msgid "When the disks return to a synced state, that field will return to ``0``. While the secondary is syncing, status about the syncing process will be shown for both hosts. For the secondary, something like the following:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_1and2.rst:47
# 1a83307bcbe94463b81c174d28865099
msgid "and for the primary, something like the following:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_1and2.rst:58
# 052d66e4c3674884b30a6a602f9757fa
msgid "Eventually the hosts will quiesce and report ``ds:UpToDate/UpToDate``. Depending on how long the secondary was down, how much data was written to the primary in the interim, and the speed of the shared network, this process could be nearly instantaneous, or could take several minutes. Your |chef server oec| processes should not need to be manipulated in any way during this recovery."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_1and2.rst:60
# 1bfa474fb1f04f3bbf716c3e6f02db01
msgid "If the secondary host is lost completely, a new host can be installed in its place, the device built, and then |drbd| started. The new host will pair with the existing primary, sync data, and be ready to take over if necessary."
msgstr ""

#: ../source/server_high_availability.rst:53
# 6ddd5c3664d14c7080e02ea6f73435ea
msgid "Scenario 3"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_3.rst:4
# 384cfccc786e48d4a335f7fb3e30f955
msgid "Trouble starts when the |drbd| primary is the host that becomes unavailable. The |drbd| process on the secondary makes no assumptions about whether or not it should automatically take over, based on the split-brain configurations in the ``drbd.conf`` file."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_3.rst:6
# 31663423fe454f06b4408e5c74b7d0c7
msgid "Basically, what this means is that when the primary becomes unavailable to the secondary without an explicit takeover being initiated, the secondary will assume that it itself is the wrong, ``split-brained`` host, and is the one unconnected and incorrect. It will take no automatic action."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_3.rst:8
# 0ee7e4ca42b24236b4e3be523a9a3c29
msgid "The status of the secondary will look something like the following:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_3.rst:17
# 810bc1a339224f51b43d51365f6808d1
msgid "The ``ds:UpToDate/Unknown`` is important; it indicates that the secondary has all the data that was on the primary and won’t lose anything if it is promoted."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_3.rst:19
# ebd32e6a38334f588d017c44fefe0ff6
msgid "If it is verified that the primary host is going to be down for a while, the secondary can be promoted to primary:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_3.rst:25
# 409d2c75477f47b7a536b46e5a98da95
msgid "at that point the status will change to something like the following:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_3.rst:34
# 32996f83f8e54ed39992dc02ec3c1b9e
msgid "Notice that ``ro`` is now ``ro:Primary/Unknown``. |chef server oec| can now be recovered by entering the following command:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_3.rst:40
# dd825dfe60224fea9a684c6dd54d2ee8
msgid "This will start up the configured services and |chef server oec| will be master on this host."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_3.rst:42
# b1e69600c9504be8937a7c8ee8ceb14c
msgid "If the original primary can be brought back online, the cluster management script run by |keepalived| will try to do a |drbd| takeover, based on that host’s original primary |chef server oec| master status."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_3.rst:44
# c51c825e25c14bd4aa602206d6b8148c
msgid "The first thing it will do is attempt to promote itself to |drbd| primary, which will fail if the disk has been written to at all while this host was down, and |keepalived| will be unable to transition back to the original master. This leaves the pair of servers in a good state, with the second back-end box as the |drbd| primary |chef server oec| master."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_3.rst:46
# a043c2137f7e44708b761ee88aedc650
msgid "|drbd| on the first back-end server will sync to the second back-end server and will become the clean secondary |fqdn|."
msgstr ""

#: ../source/server_high_availability.rst:57
# 3af05fc2089d4f25b08b7f88590e3580
msgid "Scenario 4"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_4.rst:4
# 17f1f0f112f046068c00958d7f2d4989
msgid "So far, the scenarios have not described any data loss. When the hosts in the High Availability pair are synced, either can be lost and the data will be safe."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_4.rst:6
# b07e32260d9749268bc7e6075451b2b4
msgid "If you get to a situation in which the primary host is lost and unrecoverable, but the last status of the |drbd| pair was reporting that the secondary node was in an ``Inconsistent`` state, it is very likely that some data will be lost. The |drbd| status on the remaining host will look something like the following:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_4.rst:15
# 91daa53870e94a04943ab42adae83a05
msgid "As long as good source code management is practiced with cookbooks and other files in the |chef| repository, any missing bits can be re-uploaded after there is a working cluster. In some cases, newly-created users or organizations will need to be re-created. Other actions, such as |chef| runs and uploads may fail while the cluster is in an ``Inconsistent`` state, but will be fine after there is a working cluster."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_4.rst:17
# 39f939682e5b4a45901d5789e50ffa33
msgid "When the primary back-end server has been lost while the secondary back-end server is in an ``Inconsistent`` state and it's not going to be back online quickly, the best thing to do is to provision another host to become the new |chef server oec| cluster partner for the secondary back-end server, and then build it out. If the new host has an IP address that is different from the primary back-end server, change the configuration on the secondary back-end server, and then reconfigure."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_4.rst:19
# 771bebf76c0b47d58a44bda94078157b
msgid "In this situation, |chef server oec| may be freaking out a bit, so turn off the daemons using the ``private-chef-ctl stop`` command."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_4.rst:21
# 1f9281f9b4c849dbad7f6582ff9b6601
msgid "Once the new host is identified and the |drbd| devices on that host are ready, bring up |drbd| and get it talking to the secondary back-end server. This secondary server should not want to be the primary server; it should be waiting for the old primary server to return. Start up |drbd| on the new host and verify that it is listening on the correct port and that the status in ``/proc/drbd`` is reporting that the host is up, but in the ``WFConnect: waiting for connection`` state."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_4.rst:23
# 6de4467a88cc49dc8882d1abe97a72c3
msgid "By the time you get the new node is up, the secondary back-end server may have taken itself into ``standalone`` mode, which means that it is no longer listening on the network port. In this situation, run the following commands to get the secondary back-end server to talk to the new node:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_4.rst:29
#: ../../includes_server_ha/includes_server_ha_scenario_5.rst:12
# 595a518583fb42eb9bc5533158cc7b88
# 22f2118bbbcd42628b489ce632e5ea1f
msgid "and:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_4.rst:35
# 17acfafc594e447392c48cbba2fb32de
msgid "At this point, the new host should be synchronizing with the secondary back-end server. The secondary back-end server will forget all about the data it was missing from the now-gone primary back-end server, and the process of bringing |chef server oec| back online can begin."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_4.rst:37
# 532db62c094248bea522106a2f24c1fa
msgid "Running a fast network between the primary and secondary hosts, and keeping it full throttle for |drbd| transfers, will go a long way to mitigating the any damage that may be done in the event of a loss of the primary from an un-synced cluster."
msgstr ""

#: ../source/server_high_availability.rst:61
# bc3dae000b5a44ffa33011fa128af9d5
msgid "Scenario 5"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_5.rst:4
# 15850daac4864ad0b060bf9c16bcb281
msgid "Sometimes |drbd| hedges its bets, and puts both nodes in a pair into secondary mode. When this happens, you can look at the contents of ``/proc/drbd`` on both hosts and see if either of them is showing out of sync. If they are both ``oos:0``, just pick one and promote it to primary using the ``drbdadm primary pc0`` command. If one or both of the hosts is out of sync, choose the one with the lower amount of ``oos`` and promote it to primary."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_5.rst:6
# 20244a8d5a5a4b93ac7084884d847565
msgid "If the chosen node won’t promote, run the following commands on the other host to reset its disk state:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_5.rst:18
# 6881de8eb05341c2ac2a1998aa60f03e
msgid "That will tell |drbd| to abandon what is on the node and start over, and should allow it to sync with the primary."
msgstr ""

