# SOME DESCRIPTIVE TITLE.
# Copyright (C) This work is licensed under a Creative Commons Attribution 3.0 Unported License.
# This file is distributed under the same license as the Chef Docs package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Chef Docs \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2014-03-23 21:03-0700\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

#: ../source/server_high_availability.rst:8
# 3f104855944c4199b56266d12801a45d
msgid "High Availability"
msgstr ""

#: ../../includes_server_ha/includes_server_ha.rst:4
# a60e2b0c546f4b53a6dcfa8655f3d1fa
msgid "|chef server oec| can operate in a high availability configuration that provides automated failover for stateful components in the system architecture. This configuration splits servers into two segments: front-end and back-end servers. The front-end servers handle requests to the user interface and requests that use the |api chef server|. The back-end servers handle data storage and retrieval, which consists of:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha.rst:6
# f61ada33a7914976ab965647a93dec20
msgid "|couch db|"
msgstr ""

#: ../../includes_server_ha/includes_server_ha.rst:7
# 9146191f11d84cfe8f2f359f108c9db4
msgid "|postgresql|"
msgstr ""

#: ../../includes_server_ha/includes_server_ha.rst:8
# 3c2cb8d4b3904611b4c6685b14f8fb04
msgid "|opscode solr|"
msgstr ""

#: ../../includes_server_ha/includes_server_ha.rst:9
# e9666c88d8974f619a86e085cf8efdf7
msgid "|rabbitmq|"
msgstr ""

#: ../../includes_server_ha/includes_server_ha.rst:10
# e80d32b66405448c9bad7272901af5dd
msgid "|redis|"
msgstr ""

#: ../../includes_server_ha/includes_server_ha.rst:11
# 1f6931adf6fa428aa9bf5f5861b9e063
msgid "Cookbook data"
msgstr ""

#: ../../includes_server_ha/includes_server_ha.rst:13
# 433540b105404c279d001863c8507f21
msgid "Failover on the back-end servers is achieved using the following:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha.rst:15
# 2889c40e0dc84e20bc986504f6b15211
msgid "Asynchronous block level replication of logical volume managers using |drbd|, positioned between two back-end servers"
msgstr ""

#: ../../includes_server_ha/includes_server_ha.rst:16
# bd865bfdc81f4e19a01c26b1a0599f85
msgid "A primary and backup cluster election using |vrrp| over unicast TCP/IP and |keepalived|"
msgstr ""

#: ../../includes_server_ha/includes_server_ha.rst:17
# baed5104f8b64360b810174282bb3469
msgid "A virtual IP address to the primary server, maintained based on the results of the election done by |keepalived|"
msgstr ""

#: ../../includes_server_ha/includes_server_ha.rst:21
# 1c6e89d4a3794f5bbb1ff210978e92e4
msgid "The front-end servers require load-balancers. |company_name| recommends:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha.rst:23
# 2c6e42828a8747c3bba9071a70999e32
msgid "Hardware load-balancers (such as |f5| or |netscalar|)"
msgstr ""

#: ../../includes_server_ha/includes_server_ha.rst:24
# 9baa5ab0c6394204a68848b7d11cc291
msgid "|ssl| off-loading"
msgstr ""

#: ../../includes_server_ha/includes_server_ha.rst:25
# f524a29bc66348f48a980cd3eb7fed9d
msgid "Round-robin as the load-balancing algorithm"
msgstr ""

#: ../source/server_high_availability.rst:13
# da9f49a2fa264dd2bd6ab3714e1bb759
msgid "Scalability"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scalability.rst:4
# 7e28bbfe7b2c4d0b88ddda087eb5457d
msgid "Scalability for front-end servers is achieved by horizontally scaling the number of servers."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scalability.rst:6
# bc9bcfc72a4d430fa62f8591d2461145
msgid "Scalability for back-end servers is achieved by vertically scaling the servers. For example, adding memory, CPU, and faster disks will all increase throughput from the back-end servers. Faster disks, and dedicated network interface cards will all increase the reliability of |drbd| and the responsiveness of |chef server oec|."
msgstr ""

#: ../source/server_high_availability.rst:17
# 835575e5a9bb447cba352e813767bc08
msgid "Failover and Recovery"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_failover.rst:4
# a54bbebe66974d40958fe14afff357c1
msgid "When the primary server in the cluster fails, the |vrrp| heartbeat will stop. At this point the backup server will begin transitioning to the primary state, which involves:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_failover.rst:6
# ed039a357c374095b8f6b397fb459729
msgid "Assigning the virtual IP address and sending a ``proxy-arp``"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_failover.rst:7
# e51355a30df9411ca74273a46d6b44a8
msgid "Attempting to take-over as the primary server for the |drbd| device"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_failover.rst:8
# eb9612d217ee4d1a9ac8a72b675eb678
msgid "Starting all of the back-end services"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_failover.rst:10
# e5a534ca8d274a1ca5cc35464248737d
msgid "The first step is transitioning the virtual IP address, which means that traffic will flow to the backup server while it makes the transition to being the primary server."
msgstr ""

#: ../source/server_high_availability.rst:21
# a714a5b0d225453f922be752c21c2e06
msgid "Graceful Transitions"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_transitions.rst:4
# 481db15752e44cf0b18b354e34f157df
msgid "The |keepalived| service manages the |vrrp| and cluster transitions. It should be running on both the primary and secondary servers. To transition from the primary to the secondary, simply run the following on the primary:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_transitions.rst:10
# 85386d254cf74c3ba3d8172f79f3b42a
msgid "which will initiate a failover from the primary to the secondary. This will cause the current primary to:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_transitions.rst:12
# 6f5ea6f2a656423d83d70eb90d531565
msgid "Remove the virtual IP address."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_transitions.rst:13
# c43a819b88af4314ab0b0dbbb743c392
msgid "Stop the services."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_transitions.rst:14
# 1145cd1315644f638b020f758b4c9f92
msgid "Unmount the |drbd| device."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_transitions.rst:15
# 7ca6423f1b83464680f69b0705608739
msgid "Becoming secondary for the |drbd| device."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_transitions.rst:17
# c80732706f394986aabf3eed6fd8fadb
msgid "Meanwhile, the backup will be undergoing the same steps as listed above. Use the ``ha-status`` option to view the progress:"
msgstr ""

#: ../source/server_high_availability.rst:25
# 1f359fbb60ba42b0b7a2b196249a3ed5
msgid "Status"
msgstr ""

#: ../../includes_api_chef_server/includes_api_chef_server_endpoint_status.rst:4
# b6c8dd233da846d4acaa2edc303a81ea
msgid "The ``/_status`` endpoint can be used to check the status of communications between the front and back end servers. This endpoint is located at ``/_status`` on the front end servers."
msgstr ""

#: ../../includes_api_chef_server/includes_api_chef_server_endpoint_status.rst:6
# be0ca58da1794583a4f65de5986b6c6e
msgid "**Request**"
msgstr ""

#: ../../includes_api_chef_server/includes_api_chef_server_endpoint_status.rst:12
# 0745249493104f628232ff2d8057b787
msgid "This method has no request body."
msgstr ""

#: ../../includes_api_chef_server/includes_api_chef_server_endpoint_status.rst:14
# d1399331c4a14d6ab6a92b7cbdd16b4d
msgid "**Response**"
msgstr ""

#: ../../includes_api_chef_server/includes_api_chef_server_endpoint_status.rst:16
# e791c983e7844fefa87bd0951715ccda
msgid "The response will return something like the following:"
msgstr ""

#: ../../includes_api_chef_server/includes_api_chef_server_endpoint_status.rst:31
# fce009a575f04275985122cdca9d1a3e
msgid "**Response Codes**"
msgstr ""

#: ../../includes_api_chef_server/includes_api_chef_server_endpoint_status.rst:37
# 5b375b36e0244971b69e59ccd2bc5ef4
msgid "Response Code"
msgstr ""

#: ../../includes_api_chef_server/includes_api_chef_server_endpoint_status.rst:38
# f3add8211fd5414590d1da1f77185dd0
msgid "Description"
msgstr ""

#: ../../includes_api_chef_server/includes_api_chef_server_endpoint_status.rst:39
# 10fce15ee69b413fa8a69685bd3b5372
msgid "``200``"
msgstr ""

#: ../../includes_api_chef_server/includes_api_chef_server_endpoint_status.rst:40
# e911824ad5294014977509b1bf992cfd
msgid "All communications are OK."
msgstr ""

#: ../../includes_api_chef_server/includes_api_chef_server_endpoint_status.rst:41
# d52558b5c6c3458da44528e7c5ceb5a4
msgid "``500``"
msgstr ""

#: ../../includes_api_chef_server/includes_api_chef_server_endpoint_status.rst:42
# 905571c4ea2d45a6bf99d37197bc2349
msgid "One (or more) services are down. For example:"
msgstr ""

#: ../source/server_high_availability.rst:29
# 770b7cbdb837478d84d1ecacccc03800
msgid "DRBD"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd.rst:4
# 380625f063174aac97c1158b8b09465e
msgid "|drbd| is used as part of a |ha| topology for |chef server oec|. More information about |drbd| is available from their website: http://www.drbd.org."
msgstr ""

#: ../source/server_high_availability.rst:33
# 467b44d657bf47c3a9639820befccde9
msgid "Split Brains"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_split_brain.rst:4
# 6a85bf95b7c84b0d8abb7793cbb8cba5
msgid "A ``split-brain`` event is a concept of clustered computing systems in which the cluster loses its heartbeat communication channel and becomes two unconnected pieces. Recovery from a ``split-brain`` event can be a complex issue and different clustering software packages use different methods."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_split_brain.rst:6
# ab9507eb848f4be8a8f028a3d04c17e0
msgid "Failures happen, so completely preventing a ``split-brain`` event is not an absolute possibility. However, it is possible to alleviate some of the issues that crop up in any ``split-brain`` event scenarios by maxing out the heartbeat network bandwidth and optimizing transfer protocols."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_split_brain.rst:8
# e98e21fb9098412c965e9e8803a866b7
msgid "|drbd| is a shared-nothing system. Data is replicated between hosts over a dedicated network link rather than stored on a central network-attached storage (NAS) or storage attached network (SAN) to which all hosts are connected. The most critical issue for storage in a |ha| topology is loss of or corruption of data. Maximizing the amount of data that can be passed over the wire while all systems are up and running correctly minimizes the chance that something will be lost or unrecoverable if a host goes down."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_split_brain.rst:10
# d255a40fb6634bd99d21d644222dccba
msgid "At any given time, only one |drbd| host has ``userland`` access to data, This host is referred to as the primary node. The other host runs the |drbd| daemon, but cannot mount the storage into the file system. The secondary node receives information from the primary node, and then replicates disk actions on its local storage copy (even if the partition looks like it doesn’t have a file system to which a ``mount`` command can be sent)."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_split_brain.rst:12
# 569c4de9ca6f4849a45f4def3ff515bd
msgid "The approach that |drbd| takes to ``split-brain`` event situations is to degrade all partners still alive to secondary status, and then wait for manual intervention. This is called auto-fencing, with a goal of minimizing the potential for damage to your data. When you lose one of the partners in a |ha| topology, a bit of manual intervention is required to ensure that the disks aren’t in a bad state and can be brought back up. These scenarios are discussed below, including suggestions for diagnosing and recovering from each scenario."
msgstr ""

#: ../source/server_high_availability.rst:37
# 6c726497a3b7476b8d32e51e28b800d6
msgid "Split-brain Handlers"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_handlers.rst:4
# 4f22bbe438544c36a30ad79217cdb1aa
msgid "|drbd| configuration allows for custom handlers when a ``split-brain`` event happens. The basic handler sends a notification email to a configurable email address so the issue can be investigated."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_handlers.rst:6
# 6df362457c0b4ca1a0cd0725b3b13cba
msgid "The ``drbd.conf`` file that is used with |chef server oec| specifies other built-in actions that may be taken in certain fault scenarios:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_handlers.rst:14
# e62e9f0a1f9f4056abbcae6c144ac63e
msgid "What this means:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_handlers.rst:16
# 14a9d17e3b5947618a36c2744a318bc0
msgid "after-sb-0pri: A ``split-brain`` event has been detected and neither node is the primary node. The ``discard-younger-primary`` action will roll back any changes made on the last host that was the primary node."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_handlers.rst:17
# b9299930226a4ff78210880d904adf01
msgid "after-sb-1pri: A ``split-brain`` event has been detected and only one node believes that it was the primary node when the event happened. The ``discard-secondary`` action will continue operations on the primary node and will assume that the secondary node was lost."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_handlers.rst:18
# 0447b8e5f1604501b8a428f6c5d7b1a1
msgid "after-sb-2pri: A ``split-brain`` event has been detected and both nodes believed they were primary nodes. The ``call-pri-lost-after-sb`` action will attempt to apply the ``discard-younger-primary`` from the ``0pri`` configuration to determine which host should be the primary node. Once determined, the other host takes action to become the secondary node."
msgstr ""

#: ../source/server_high_availability.rst:41
# 9a6abfc845e14834b3e6c097ab5152d6
msgid "Assumptions"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_assumptions.rst:4
# 6eb36f89bb2542a887648ae969327b3b
msgid "The following assumptions exist when |chef private| is deployed in a |ha| topology:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_assumptions.rst:6
# 239a242dd0c24a8593a85f9259465de4
msgid "The back-end processes run on two hosts: ``BE1`` and ``BE2``. ``BE1`` is the |drbd| primary and |chef server oec| master; ``BE2`` is the |drbd| secondary and the |chef server oec| backup"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_assumptions.rst:7
# 9ec51ea39d9d420f88f4c961c343f348
msgid "The back-end uses |keepalived| and a dedicated network interface for heartbeat"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_assumptions.rst:8
# b5b51d489c6f49a6845949bcbd59b8dc
msgid "The back-end uses |drbd| for file redundancy"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_assumptions.rst:10
# a8f27a107d5441e5b661ced3606e6202
msgid "On each host, its own status is reported first, and then the status of its remote partner."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_assumptions.rst:12
# 21cd34005c55411f8bcdc7d8c57ab7d8
msgid "When both the primary and secondary nodes are running and behaving as expected, the contents of ``/proc/drbd`` on the primary node will look similar to the following:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_assumptions.rst:21
# ecf0059ba7e449269691b8775976284f
msgid "On the secondary node, the status will look similar to the following:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_assumptions.rst:30
# 2182047534b641d1bc8ffd001cfe3b0d
msgid "For information about the settings in this file, see the |drbd| website: http://www.drbd.org/users-guide/ch-admin.html."
msgstr ""

#: ../source/server_high_availability.rst:45
# fa74d6c31e8748e1bd8aadd355a7bfba
msgid "Failure Scenarios"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario.rst:4
# ffafd2f9ab184c14a664ef74bd755890
msgid "The following four common scenarios are discussed:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario.rst:6
# 270c8ea2a2694b7ea3632cfdf8b51df9
msgid "Back-end server #2 fails gracefully (all data is synced)"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario.rst:7
# fba76f1426e143a6a0fe5641f79d065b
msgid "Back-end server #2 hard fails badly (unsynced data)"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario.rst:8
# 0d93e67de84a499da02feba92bb794f1
msgid "Back-end server #1 fails gracefully (all data is synced)"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario.rst:9
# f7683ce18eef49e1a2ee020ecc5f0db6
msgid "Back-end server #1 hard fails badly (unsynced data)"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario.rst:10
# f9061abbca6347c69f8507322bb39aed
msgid "Both hosts are up as secondary, and |chef server oec| is unhappy"
msgstr ""

#: ../source/server_high_availability.rst:49
# 9e1aa78472044e88a6ac9a4427eaa04e
msgid "Scenarios 1 and 2"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_1and2.rst:4
# ff1d075915844a8098657891b47aa24e
msgid "When the acting backup server fails, |drbd| on the master will continue to function in primary mode, whether the |drbd| on the secondary was shut down gracefully or became unavailable unexpectedly. Verify that |drbd| is functioning by running ``drbdadm role pc0`` on the primary:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_1and2.rst:12
# 0740e96003c440a1ace6e5cc740c6f5a
msgid "You can see the full status by running cat ``/proc/drbd``:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_1and2.rst:21
# 0c842375740c4509b799e511d2695462
msgid "The disk partition is still mounted into the file system and can be used as normal."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_1and2.rst:23
# c10e0e9fc5f94e78bbf39803be32a33f
msgid "When the secondary becomes available again, two things may happen:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_1and2.rst:25
# 711cedcfcb864e2c8f1ea9d5756b5b5a
msgid "If the status of the secondary reports ``Inconsistent`` or ``UpToDate`` without manual intervention, all is well."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_1and2.rst:26
# 0faf3684c0d24e71bef3562184ba09a1
msgid "If it remains ``DUnknown``, |drbd| on the secondary can be manually restarted and it will start to sync. The ``DUnknown`` status is the report which indicates that |drbd| sees no network connection to its partner."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_1and2.rst:28
# 3b9de7e813134684a5aa48d7692afb69
msgid "The last field in the ``/prod/drbd`` file (``oos``) reports how far the primary is out of sync with its partner. If the secondary is down and there are a lot of writes on the primary, this number will increase. For example:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_1and2.rst:37
# f2800c9781874bc3b51923ebd84f5cb6
msgid "When the disks return to a synced state, that field will return to ``0``. While the secondary is syncing, status about the syncing process will be shown for both hosts. For the secondary, something like the following:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_1and2.rst:47
# 3fdcb4c7c02941b8b79690132c3aae48
msgid "and for the primary, something like the following:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_1and2.rst:58
# 013637ea60c74143b779daa6ba3aaeaa
msgid "Eventually the hosts will quiesce and report ``ds:UpToDate/UpToDate``. Depending on how long the secondary was down, how much data was written to the primary in the interim, and the speed of the shared network, this process could be nearly instantaneous, or could take several minutes. Your |chef server oec| processes should not need to be manipulated in any way during this recovery."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_1and2.rst:60
# 8235008649b2419b9e221cec8b7d16cb
msgid "If the secondary host is lost completely, a new host can be installed in its place, the device built, and then |drbd| started. The new host will pair with the existing primary, sync data, and be ready to take over if necessary."
msgstr ""

#: ../source/server_high_availability.rst:53
# 65f9e22b976e45ae8a2d3261627f5c23
msgid "Scenario 3"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_3.rst:4
# b222de9104e041659b2b0e3e87d01e50
msgid "Trouble starts when the |drbd| primary is the host that becomes unavailable. The |drbd| process on the secondary makes no assumptions about whether or not it should automatically take over, based on the split-brain configurations in the ``drbd.conf`` file."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_3.rst:6
# 91b98150daa1493e904ef2f10ab3c161
msgid "Basically, what this means is that when the primary becomes unavailable to the secondary without an explicit takeover being initiated, the secondary will assume that it itself is the wrong, ``split-brained`` host, and is the one unconnected and incorrect. It will take no automatic action."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_3.rst:8
# 65149af46bca41499108d47f8c4112ed
msgid "The status of the secondary will look something like the following:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_3.rst:17
# 40178d5ef81942db98e218f19051c810
msgid "The ``ds:UpToDate/Unknown`` is important; it indicates that the secondary has all the data that was on the primary and won’t lose anything if it is promoted."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_3.rst:19
# 1b79e70aefff4eadabdf956c16914c85
msgid "If it is verified that the primary host is going to be down for a while, the secondary can be promoted to primary:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_3.rst:25
# 2760fd21961b4809bc5dedee126a198d
msgid "at that point the status will change to something like the following:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_3.rst:34
# 8fd12f7b2dc14671909cefc42a66760a
msgid "Notice that ``ro`` is now ``ro:Primary/Unknown``. |chef server oec| can now be recovered by entering the following command:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_3.rst:40
# 30f42de9c2194042a26b2fdf71b0dc64
msgid "This will start up the configured services and |chef server oec| will be master on this host."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_3.rst:42
# 2ae5e9756de248e2b2b25232b7b5b135
msgid "If the original primary can be brought back online, the cluster management script run by |keepalived| will try to do a |drbd| takeover, based on that host’s original primary |chef server oec| master status."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_3.rst:44
# 40505cecbdbc4bfd92fe37ffc274f975
msgid "The first thing it will do is attempt to promote itself to |drbd| primary, which will fail if the disk has been written to at all while this host was down, and |keepalived| will be unable to transition back to the original master. This leaves the pair of servers in a good state, with the second back-end box as the |drbd| primary |chef server oec| master."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_3.rst:46
# bb3b842320864dc28f9454f5c99a3b58
msgid "|drbd| on the first back-end server will sync to the second back-end server and will become the clean secondary |fqdn|."
msgstr ""

#: ../source/server_high_availability.rst:57
# 5e8b8b93e15347d4a89f9ecee73aa215
msgid "Scenario 4"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_4.rst:4
# 45f3b9f542df44ed910d16943d2c4c6d
msgid "So far, the scenarios have not described any data loss. When the hosts in the High Availability pair are synced, either can be lost and the data will be safe."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_4.rst:6
# 5c6514cc55f4481c9c06c120814156d4
msgid "If you get to a situation in which the primary host is lost and unrecoverable, but the last status of the |drbd| pair was reporting that the secondary node was in an ``Inconsistent`` state, it is very likely that some data will be lost. The |drbd| status on the remaining host will look something like the following:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_4.rst:15
# 43f1d181804942d1996a31a8d8fb8035
msgid "As long as good source code management is practiced with cookbooks and other files in the |chef| repository, any missing bits can be re-uploaded after there is a working cluster. In some cases, newly-created users or organizations will need to be re-created. Other actions, such as |chef| runs and uploads may fail while the cluster is in an ``Inconsistent`` state, but will be fine after there is a working cluster."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_4.rst:17
# ac3b4b3435634b76bccd4433c2bc90db
msgid "When the primary back-end server has been lost while the secondary back-end server is in an ``Inconsistent`` state and it's not going to be back online quickly, the best thing to do is to provision another host to become the new |chef server oec| cluster partner for the secondary back-end server, and then build it out. If the new host has an IP address that is different from the primary back-end server, change the configuration on the secondary back-end server, and then reconfigure."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_4.rst:19
# a18da318ef8d4e84859e7d5fd74c9e76
msgid "In this situation, |chef server oec| may be freaking out a bit, so turn off the daemons using the ``private-chef-ctl stop`` command."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_4.rst:21
# 957537db8dc947c8a3876bdad16384de
msgid "Once the new host is identified and the |drbd| devices on that host are ready, bring up |drbd| and get it talking to the secondary back-end server. This secondary server should not want to be the primary server; it should be waiting for the old primary server to return. Start up |drbd| on the new host and verify that it is listening on the correct port and that the status in ``/proc/drbd`` is reporting that the host is up, but in the ``WFConnect: waiting for connection`` state."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_4.rst:23
# 91d7c1db861349558c5be452b48a22d1
msgid "By the time you get the new node is up, the secondary back-end server may have taken itself into ``standalone`` mode, which means that it is no longer listening on the network port. In this situation, run the following commands to get the secondary back-end server to talk to the new node:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_4.rst:29
#: ../../includes_server_ha/includes_server_ha_scenario_5.rst:12
# 971f36317e0e4649aa8725ae2ac47daa
# 2218266a837f4567908994c41490854c
msgid "and:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_4.rst:35
# 495b26a634b049fb9888924910cd11d0
msgid "At this point, the new host should be synchronizing with the secondary back-end server. The secondary back-end server will forget all about the data it was missing from the now-gone primary back-end server, and the process of bringing |chef server oec| back online can begin."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_4.rst:37
# e08a174befe846d1b55587da90e38579
msgid "Running a fast network between the primary and secondary hosts, and keeping it full throttle for |drbd| transfers, will go a long way to mitigating the any damage that may be done in the event of a loss of the primary from an un-synced cluster."
msgstr ""

#: ../source/server_high_availability.rst:61
# 3a82857fbc364d5a8e463e274c38389f
msgid "Scenario 5"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_5.rst:4
# feec8ecf3bd1415196499acf38072c10
msgid "Sometimes |drbd| hedges its bets, and puts both nodes in a pair into secondary mode. When this happens, you can look at the contents of ``/proc/drbd`` on both hosts and see if either of them is showing out of sync. If they are both ``oos:0``, just pick one and promote it to primary using the ``drbdadm primary pc0`` command. If one or both of the hosts is out of sync, choose the one with the lower amount of ``oos`` and promote it to primary."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_5.rst:6
# 75be7318e3574493aa73a5f130df0abd
msgid "If the chosen node won’t promote, run the following commands on the other host to reset its disk state:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_5.rst:18
# 4d3bb1975c8a4449a0ce1e53b1dbb960
msgid "That will tell |drbd| to abandon what is on the node and start over, and should allow it to sync with the primary."
msgstr ""

