# SOME DESCRIPTIVE TITLE.
# Copyright (C) This work is licensed under a Creative Commons Attribution 3.0 Unported License.
# This file is distributed under the same license as the Chef Docs package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Chef Docs \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2014-05-14 13:18-0700\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

#: ../source/server_high_availability.rst:8
# f27c6d6a00f24f80b3f6ad90c73eec0d
msgid "High Availability"
msgstr ""

#: ../../includes_server_ha/includes_server_ha.rst:4
# 281a892b6752409b9142454b9a1bd7d7
msgid "|chef server oec| can operate in a high availability configuration that provides automated failover for stateful components in the system architecture. This configuration splits servers into two segments: front-end and back-end servers. The front-end servers handle requests to the user interface and requests that use the |api chef server|. The back-end servers handle data storage and retrieval, which consists of:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha.rst:6
# f56b70c027524938aff772a4e025c66c
msgid "|couch db|"
msgstr ""

#: ../../includes_server_ha/includes_server_ha.rst:7
# fd15d2074d7f40938b6634fcb4d234cc
msgid "|postgresql|"
msgstr ""

#: ../../includes_server_ha/includes_server_ha.rst:8
# a91750f8025d4443a2189523df8dd487
msgid "|opscode solr|"
msgstr ""

#: ../../includes_server_ha/includes_server_ha.rst:9
# 516d3dfe30d94de688fb689862e80bca
msgid "|rabbitmq|"
msgstr ""

#: ../../includes_server_ha/includes_server_ha.rst:10
# 31bc90ebbbe541c682e03aa6d47767de
msgid "|redis|"
msgstr ""

#: ../../includes_server_ha/includes_server_ha.rst:11
# ea5d99a4c0d74082a8a92562936fe2bb
msgid "Cookbook data"
msgstr ""

#: ../../includes_server_ha/includes_server_ha.rst:13
# da704bb0fe21475eba0f5d45fe572753
msgid "Failover on the back-end servers is achieved using the following:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha.rst:15
# 122d46c5a04f4b2995de04658eef407b
msgid "Asynchronous block level replication of logical volume managers using |drbd|, positioned between two back-end servers"
msgstr ""

#: ../../includes_server_ha/includes_server_ha.rst:16
# b3a72ebca437463384a03c01c3b4f835
msgid "A primary and backup cluster election using |vrrp| over unicast TCP/IP and |keepalived|"
msgstr ""

#: ../../includes_server_ha/includes_server_ha.rst:17
# 55aa0204909244229f23cc9dd6270648
msgid "A virtual IP address to the primary server, maintained based on the results of the election done by |keepalived|"
msgstr ""

#: ../../includes_server_ha/includes_server_ha.rst:21
# a7bbdbc9e4d04931824a8ea5260ff6c8
msgid "The front-end servers require load-balancers. |company_name| recommends:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha.rst:23
# 82fea612e2374174ba793aea032d5fbf
msgid "Hardware load-balancers (such as |f5| or |netscalar|)"
msgstr ""

#: ../../includes_server_ha/includes_server_ha.rst:24
# a5f75aafce9148a4a035bf276acc33f5
msgid "|ssl| off-loading"
msgstr ""

#: ../../includes_server_ha/includes_server_ha.rst:25
# df09958f799f4249a2d9ba82f5b03283
msgid "Round-robin as the load-balancing algorithm"
msgstr ""

#: ../source/server_high_availability.rst:13
# 7548984db8194976901c5e68c8841bb0
msgid "Scalability"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scalability.rst:4
# 6597b7e6e3a942938abb85247b8d2910
msgid "Scalability for front-end servers is achieved by horizontally scaling the number of servers."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scalability.rst:6
# 71876f6c6c2243fa8ff0d89f130a6eb3
msgid "Scalability for back-end servers is achieved by vertically scaling the servers. For example, adding memory, CPU, and faster disks will all increase throughput from the back-end servers. Faster disks, and dedicated network interface cards will all increase the reliability of |drbd| and the responsiveness of |chef server oec|."
msgstr ""

#: ../source/server_high_availability.rst:17
# ddb44739ab574461aeb34c3972fe4f16
msgid "Failover and Recovery"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_failover.rst:4
# e58dd7de6a864db9961abf946a86555c
msgid "When the primary server in the cluster fails, the |vrrp| heartbeat will stop. At this point the backup server will begin transitioning to the primary state, which involves:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_failover.rst:6
# c000276675d94b8a9bf3219770b7e7c1
msgid "Assigning the virtual IP address and sending a ``proxy-arp``"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_failover.rst:7
# 42ee1c797cc94a05a268b43fdff2f371
msgid "Attempting to take-over as the primary server for the |drbd| device"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_failover.rst:8
# c8616091fdfb4938aca6cd87b80c4d25
msgid "Starting all of the back-end services"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_failover.rst:10
# 0fdcc074103042ee924996484b4b75f8
msgid "The first step is transitioning the virtual IP address, which means that traffic will flow to the backup server while it makes the transition to being the primary server."
msgstr ""

#: ../source/server_high_availability.rst:21
# 10ce642c95a0491b8d89ea5ec9c1a3f8
msgid "Graceful Transitions"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_transitions.rst:4
# 7143fccd401344cc8aa8ddcd43707613
msgid "The |keepalived| service manages the |vrrp| and cluster transitions. It should be running on both the primary and secondary servers. To transition from the primary to the secondary, simply run the following on the primary:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_transitions.rst:10
# f06faa88df4c41d2a31e82964f79b703
msgid "which will initiate a failover from the primary to the secondary. This will cause the current primary to:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_transitions.rst:12
# 8e19b0fac6db44d782aa7c965a2c19d3
msgid "Remove the virtual IP address."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_transitions.rst:13
# 5ac75696c6d041e083ffd792ae295757
msgid "Stop the services."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_transitions.rst:14
# 7873cffc064d4ff79e254c929b91f003
msgid "Unmount the |drbd| device."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_transitions.rst:15
# fa5647d877394c9cad76628ccba465de
msgid "Becoming secondary for the |drbd| device."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_transitions.rst:17
# b91cf89ee631458d93d4c6317b976088
msgid "Meanwhile, the backup will be undergoing the same steps as listed above. Use the ``ha-status`` option to view the progress:"
msgstr ""

#: ../source/server_high_availability.rst:25
# daeab3a6794841348e73984d3feaf3e3
msgid "Status"
msgstr ""

#: ../../includes_api_chef_server/includes_api_chef_server_endpoint_status.rst:4
# fc8fac8baa804b3a9b433c2d11bb508d
msgid "The ``/_status`` endpoint can be used to check the status of communications between the front and back end servers. This endpoint is located at ``/_status`` on the front end servers."
msgstr ""

#: ../../includes_api_chef_server/includes_api_chef_server_endpoint_status.rst:6
# d3454a4338fd4dacabd3c1b77b72c46a
msgid "**Request**"
msgstr ""

#: ../../includes_api_chef_server/includes_api_chef_server_endpoint_status.rst:12
# b70bea91c24b4855938f42707d422215
msgid "This method has no request body."
msgstr ""

#: ../../includes_api_chef_server/includes_api_chef_server_endpoint_status.rst:14
# 7319e8fd2f5b4bad97878aa7cdec30a1
msgid "**Response**"
msgstr ""

#: ../../includes_api_chef_server/includes_api_chef_server_endpoint_status.rst:16
# 535233cd6ecd4e38a5c1bea65e5bdc93
msgid "The response will return something like the following:"
msgstr ""

#: ../../includes_api_chef_server/includes_api_chef_server_endpoint_status.rst:31
# a2b0aa471002423982c8aa4267aa98dc
msgid "**Response Codes**"
msgstr ""

#: ../../includes_api_chef_server/includes_api_chef_server_endpoint_status.rst:37
# e0bebd20b28642a083bf165484704dca
msgid "Response Code"
msgstr ""

#: ../../includes_api_chef_server/includes_api_chef_server_endpoint_status.rst:38
# 9968c5125b974c048a1f758c6100f84f
msgid "Description"
msgstr ""

#: ../../includes_api_chef_server/includes_api_chef_server_endpoint_status.rst:39
# 9f69d3f9ba6a4bb19ab5eee1d81f2e25
msgid "``200``"
msgstr ""

#: ../../includes_api_chef_server/includes_api_chef_server_endpoint_status.rst:40
# 86f16b13aee94762add75232b6538a58
msgid "All communications are OK."
msgstr ""

#: ../../includes_api_chef_server/includes_api_chef_server_endpoint_status.rst:41
# 4d59fc3fd5c642c69769cd1c2a718c22
msgid "``500``"
msgstr ""

#: ../../includes_api_chef_server/includes_api_chef_server_endpoint_status.rst:42
# 1226459435b040629d4d6c6b4f6d902c
msgid "One (or more) services are down. For example:"
msgstr ""

#: ../source/server_high_availability.rst:29
# 59552c9e1ff745648d6a5aeb436c51eb
msgid "DRBD"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd.rst:4
# 9ffd7fe84e8045209e8851d2b388d9d7
msgid "|drbd| is used as part of a |ha| topology for |chef server oec|. More information about |drbd| is available from their website: http://www.drbd.org."
msgstr ""

#: ../source/server_high_availability.rst:33
# 4c2ef489dd274759ab6861fbea5b6a4b
msgid "Split Brains"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_split_brain.rst:4
# 42a51ff5f7ab4492945b0296ae16dbda
msgid "A ``split-brain`` event is a concept of clustered computing systems in which the cluster loses its heartbeat communication channel and becomes two unconnected pieces. Recovery from a ``split-brain`` event can be a complex issue and different clustering software packages use different methods."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_split_brain.rst:6
# aeb9f4fd71ca42b3842b7d210eb750aa
msgid "Failures happen, so completely preventing a ``split-brain`` event is not an absolute possibility. However, it is possible to alleviate some of the issues that crop up in any ``split-brain`` event scenarios by maxing out the heartbeat network bandwidth and optimizing transfer protocols."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_split_brain.rst:8
# f9802c14064a4a4bae0812f25ce4a292
msgid "|drbd| is a shared-nothing system. Data is replicated between hosts over a dedicated network link rather than stored on a central network-attached storage (NAS) or storage attached network (SAN) to which all hosts are connected. The most critical issue for storage in a |ha| topology is loss of or corruption of data. Maximizing the amount of data that can be passed over the wire while all systems are up and running correctly minimizes the chance that something will be lost or unrecoverable if a host goes down."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_split_brain.rst:10
# 89c08230746f49778246a3422b77b7bb
msgid "At any given time, only one |drbd| host has ``userland`` access to data, This host is referred to as the primary node. The other host runs the |drbd| daemon, but cannot mount the storage into the file system. The secondary node receives information from the primary node, and then replicates disk actions on its local storage copy (even if the partition looks like it doesn’t have a file system to which a ``mount`` command can be sent)."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_split_brain.rst:12
# e1fb7db8f3de4d7ba59e8640c3c1bbaf
msgid "The approach that |drbd| takes to ``split-brain`` event situations is to degrade all partners still alive to secondary status, and then wait for manual intervention. This is called auto-fencing, with a goal of minimizing the potential for damage to your data. When you lose one of the partners in a |ha| topology, a bit of manual intervention is required to ensure that the disks aren’t in a bad state and can be brought back up. These scenarios are discussed below, including suggestions for diagnosing and recovering from each scenario."
msgstr ""

#: ../source/server_high_availability.rst:37
# ec98836faa3c4b9f87828ca770609128
msgid "Split-brain Handlers"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_handlers.rst:4
# 4167b27d7222463b925a9d296360b419
msgid "|drbd| configuration allows for custom handlers when a ``split-brain`` event happens. The basic handler sends a notification email to a configurable email address so the issue can be investigated."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_handlers.rst:6
# dab40f1c8cc34d4daf8bbe30431cb8e9
msgid "The ``drbd.conf`` file that is used with |chef server oec| specifies other built-in actions that may be taken in certain fault scenarios:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_handlers.rst:14
# b293dca7a12c412b9304a7992412e866
msgid "What this means:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_handlers.rst:16
# 6005963e27dc4c279e3546895c5ac35c
msgid "after-sb-0pri: A ``split-brain`` event has been detected and neither node is the primary node. The ``discard-younger-primary`` action will roll back any changes made on the last host that was the primary node."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_handlers.rst:17
# 7deaf54265134a0f9e603abd71e38eb4
msgid "after-sb-1pri: A ``split-brain`` event has been detected and only one node believes that it was the primary node when the event happened. The ``discard-secondary`` action will continue operations on the primary node and will assume that the secondary node was lost."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_handlers.rst:18
# 5759c0b348654822a61c7a951f9b6bcb
msgid "after-sb-2pri: A ``split-brain`` event has been detected and both nodes believed they were primary nodes. The ``call-pri-lost-after-sb`` action will attempt to apply the ``discard-younger-primary`` from the ``0pri`` configuration to determine which host should be the primary node. Once determined, the other host takes action to become the secondary node."
msgstr ""

#: ../source/server_high_availability.rst:41
# 3e0ad8f49d1d477ab4c3dfcb7867c441
msgid "Assumptions"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_assumptions.rst:4
# 6a11bb409f8a46b28b66824e5ec47105
msgid "The following assumptions exist when |chef private| is deployed in a |ha| topology:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_assumptions.rst:6
# d016dc304ec3420b9aaeefda2f9e49bf
msgid "The back-end processes run on two hosts: ``BE1`` and ``BE2``. ``BE1`` is the |drbd| primary and |chef server oec| master; ``BE2`` is the |drbd| secondary and the |chef server oec| backup"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_assumptions.rst:7
# 943fd7bca37743b4be602c3d5f7f4f7a
msgid "The back-end uses |keepalived| and a dedicated network interface for heartbeat"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_assumptions.rst:8
# 87644c36b21a4871a5b19618ef7619f1
msgid "The back-end uses |drbd| for file redundancy"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_assumptions.rst:10
# f24753ce0d134de09b2e47533872b302
msgid "On each host, its own status is reported first, and then the status of its remote partner."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_assumptions.rst:12
# 7d716002b57e45aa87bb9bccf73493df
msgid "When both the primary and secondary nodes are running and behaving as expected, the contents of ``/proc/drbd`` on the primary node will look similar to the following:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_assumptions.rst:21
# 699f642a40f6458ca75a439b698cd880
msgid "On the secondary node, the status will look similar to the following:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_drbd_assumptions.rst:30
# 231825439b4741f0b322675230021700
msgid "For information about the settings in this file, see the |drbd| website: http://www.drbd.org/users-guide/ch-admin.html."
msgstr ""

#: ../source/server_high_availability.rst:45
# 520015b4602443a89dd4cab9237b14a5
msgid "Failure Scenarios"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario.rst:4
# 9732e08a7c7d405da96f0662195bdf7f
msgid "The following four common scenarios are discussed:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario.rst:6
# 138161b73e7248a7a20e48ab7912ea6f
msgid "Back-end server #2 fails gracefully (all data is synced)"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario.rst:7
# 3d0987124d9f4242893df077674e24f1
msgid "Back-end server #2 hard fails badly (unsynced data)"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario.rst:8
# 066a0611b5554f09b7f73d66b0c14651
msgid "Back-end server #1 fails gracefully (all data is synced)"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario.rst:9
# 87e898c895ba4d5ebf9756bad56a4bf1
msgid "Back-end server #1 hard fails badly (unsynced data)"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario.rst:10
# 475b6d6fdf1a405b92a2be452caad9e2
msgid "Both hosts are up as secondary, and |chef server oec| is unhappy"
msgstr ""

#: ../source/server_high_availability.rst:49
# ff2dc303ffa148dfbeea6973867e675f
msgid "Scenarios 1 and 2"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_1and2.rst:4
# 3ef4b010563c4ae2b2a545c301ae04c4
msgid "When the acting backup server fails, |drbd| on the master will continue to function in primary mode, whether the |drbd| on the secondary was shut down gracefully or became unavailable unexpectedly. Verify that |drbd| is functioning by running ``drbdadm role pc0`` on the primary:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_1and2.rst:12
# f3adeb5d11a4449f9a6138613c4a4a17
msgid "You can see the full status by running cat ``/proc/drbd``:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_1and2.rst:21
# 034ceacc744a47c9b347b9c424177c77
msgid "The disk partition is still mounted into the file system and can be used as normal."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_1and2.rst:23
# 90e7322afb7b4a8fa3d35382a7248cc3
msgid "When the secondary becomes available again, two things may happen:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_1and2.rst:25
# a9f4d75e09484e13be5670578678e8b9
msgid "If the status of the secondary reports ``Inconsistent`` or ``UpToDate`` without manual intervention, all is well."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_1and2.rst:26
# ac8f606fefd54b47a06a256b6ab239be
msgid "If it remains ``DUnknown``, |drbd| on the secondary can be manually restarted and it will start to sync. The ``DUnknown`` status is the report which indicates that |drbd| sees no network connection to its partner."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_1and2.rst:28
# 4b5f84f6273849059a3f4f25d57ba236
msgid "The last field in the ``/prod/drbd`` file (``oos``) reports how far the primary is out of sync with its partner. If the secondary is down and there are a lot of writes on the primary, this number will increase. For example:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_1and2.rst:37
# c2b16db3ddcc45e29677319abcd716b0
msgid "When the disks return to a synced state, that field will return to ``0``. While the secondary is syncing, status about the syncing process will be shown for both hosts. For the secondary, something like the following:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_1and2.rst:47
# 39b01c76a3a24a85981c665b7160b4fa
msgid "and for the primary, something like the following:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_1and2.rst:58
# 77a083b8c2264c8fa602cbc568c98404
msgid "Eventually the hosts will quiesce and report ``ds:UpToDate/UpToDate``. Depending on how long the secondary was down, how much data was written to the primary in the interim, and the speed of the shared network, this process could be nearly instantaneous, or could take several minutes. Your |chef server oec| processes should not need to be manipulated in any way during this recovery."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_1and2.rst:60
# f1a18d78cf624422921322428d50995d
msgid "If the secondary host is lost completely, a new host can be installed in its place, the device built, and then |drbd| started. The new host will pair with the existing primary, sync data, and be ready to take over if necessary."
msgstr ""

#: ../source/server_high_availability.rst:53
# b9221085c4e84409baef42caefcbd019
msgid "Scenario 3"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_3.rst:4
# 542f4e577b2847c7b2a26d900a3efbb0
msgid "Trouble starts when the |drbd| primary is the host that becomes unavailable. The |drbd| process on the secondary makes no assumptions about whether or not it should automatically take over, based on the split-brain configurations in the ``drbd.conf`` file."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_3.rst:6
# 9f417b03ff4e4a5a94ba8f2d07c5148d
msgid "Basically, what this means is that when the primary becomes unavailable to the secondary without an explicit takeover being initiated, the secondary will assume that it itself is the wrong, ``split-brained`` host, and is the one unconnected and incorrect. It will take no automatic action."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_3.rst:8
# 71510bc274d747ba8e9def6773043635
msgid "The status of the secondary will look something like the following:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_3.rst:17
# 864c30b030ac4e3db00ff0935c575c95
msgid "The ``ds:UpToDate/Unknown`` is important; it indicates that the secondary has all the data that was on the primary and won’t lose anything if it is promoted."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_3.rst:19
# df88950ca044424dad8550b103b7fa96
msgid "If it is verified that the primary host is going to be down for a while, the secondary can be promoted to primary:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_3.rst:25
# 77c6d98e13c64708af4d71c66fffbe37
msgid "at that point the status will change to something like the following:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_3.rst:34
# ec4f58ea0d1346afb1a6f8798e8b5049
msgid "Notice that ``ro`` is now ``ro:Primary/Unknown``. |chef server oec| can now be recovered by entering the following command:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_3.rst:40
# c953c5dac61947638283c1ac4966550e
msgid "This will start up the configured services and |chef server oec| will be master on this host."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_3.rst:42
# c2cd31defd704bdfbeb337b8d177ca63
msgid "If the original primary can be brought back online, the cluster management script run by |keepalived| will try to do a |drbd| takeover, based on that host’s original primary |chef server oec| master status."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_3.rst:44
# cc2c8cc9d7cb4893a11425204d4ca8c8
msgid "The first thing it will do is attempt to promote itself to |drbd| primary, which will fail if the disk has been written to at all while this host was down, and |keepalived| will be unable to transition back to the original master. This leaves the pair of servers in a good state, with the second back-end box as the |drbd| primary |chef server oec| master."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_3.rst:46
# 9951dc1bf1ec4269ba30ffb77da79f02
msgid "|drbd| on the first back-end server will sync to the second back-end server and will become the clean secondary |fqdn|."
msgstr ""

#: ../source/server_high_availability.rst:57
# dd73a8302b894282b2d6107f6df5535a
msgid "Scenario 4"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_4.rst:4
# 53d2ffb0a5f842f7b4310e7a9e5916d1
msgid "So far, the scenarios have not described any data loss. When the hosts in the High Availability pair are synced, either can be lost and the data will be safe."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_4.rst:6
# 0299bc1e509841e2b6051f8d63646def
msgid "If you get to a situation in which the primary host is lost and unrecoverable, but the last status of the |drbd| pair was reporting that the secondary node was in an ``Inconsistent`` state, it is very likely that some data will be lost. The |drbd| status on the remaining host will look something like the following:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_4.rst:15
# ea08c05be4a145e6a42d1f96faf219b2
msgid "As long as good source code management is practiced with cookbooks and other files in the |chef| repository, any missing bits can be re-uploaded after there is a working cluster. In some cases, newly-created users or organizations will need to be re-created. Other actions, such as |chef| runs and uploads may fail while the cluster is in an ``Inconsistent`` state, but will be fine after there is a working cluster."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_4.rst:17
# 2728f07624e54d438e07a2518ef4d8f5
msgid "When the primary back-end server has been lost while the secondary back-end server is in an ``Inconsistent`` state and it's not going to be back online quickly, the best thing to do is to provision another host to become the new |chef server oec| cluster partner for the secondary back-end server, and then build it out. If the new host has an IP address that is different from the primary back-end server, change the configuration on the secondary back-end server, and then reconfigure."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_4.rst:19
# 3d0b37a7746a4639aeef98cf3209ca6b
msgid "In this situation, |chef server oec| may be freaking out a bit, so turn off the daemons using the ``private-chef-ctl stop`` command."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_4.rst:21
# b6f14f3a29844f7e8534068d05c78d9a
msgid "Once the new host is identified and the |drbd| devices on that host are ready, bring up |drbd| and get it talking to the secondary back-end server. This secondary server should not want to be the primary server; it should be waiting for the old primary server to return. Start up |drbd| on the new host and verify that it is listening on the correct port and that the status in ``/proc/drbd`` is reporting that the host is up, but in the ``WFConnect: waiting for connection`` state."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_4.rst:23
# e18f89a9d40d46399513867d9d958759
msgid "By the time you get the new node is up, the secondary back-end server may have taken itself into ``standalone`` mode, which means that it is no longer listening on the network port. In this situation, run the following commands to get the secondary back-end server to talk to the new node:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_4.rst:29
#: ../../includes_server_ha/includes_server_ha_scenario_5.rst:12
# 1e1059e158724dc0af0bc50bd6f419b8
# a0961a78eaed449da8b74dd44785c545
msgid "and:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_4.rst:35
# d4e031e065234a74a5bb4104fec786b2
msgid "At this point, the new host should be synchronizing with the secondary back-end server. The secondary back-end server will forget all about the data it was missing from the now-gone primary back-end server, and the process of bringing |chef server oec| back online can begin."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_4.rst:37
# c9cc474951e4492f93e06152923f0ce1
msgid "Running a fast network between the primary and secondary hosts, and keeping it full throttle for |drbd| transfers, will go a long way to mitigating the any damage that may be done in the event of a loss of the primary from an un-synced cluster."
msgstr ""

#: ../source/server_high_availability.rst:61
# dcab7f6f29944a6491c60228f3aac12c
msgid "Scenario 5"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_5.rst:4
# ed74a01e78bf4266bd9ebe99405d6adf
msgid "Sometimes |drbd| hedges its bets, and puts both nodes in a pair into secondary mode. When this happens, you can look at the contents of ``/proc/drbd`` on both hosts and see if either of them is showing out of sync. If they are both ``oos:0``, just pick one and promote it to primary using the ``drbdadm primary pc0`` command. If one or both of the hosts is out of sync, choose the one with the lower amount of ``oos`` and promote it to primary."
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_5.rst:6
# f20a7b09e0034480a31d08f0cba5a75c
msgid "If the chosen node won’t promote, run the following commands on the other host to reset its disk state:"
msgstr ""

#: ../../includes_server_ha/includes_server_ha_scenario_5.rst:18
# 6e5f17c397374e6982a4c5ecb72d14d0
msgid "That will tell |drbd| to abandon what is on the node and start over, and should allow it to sync with the primary."
msgstr ""

